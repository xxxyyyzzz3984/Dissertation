
\pdfminorversion=4
\documentclass[letterpaper,12pt]{article}
\usepackage[top=1in, bottom=1in, left=1.25in, right=1.25in]{geometry}
\usepackage{setspace}
\setcounter{secnumdepth}{3} % this number depends on your depth of sections
\setcounter{tocdepth}{3} % this number should be equal to secnumdepth in previous
%\usepackage{subfigure}
%\usepackage[subfigure]{tocloft}
\usepackage{subcaption}
\usepackage{tocstyle}
\usepackage{mathtools}

\renewcommand{\contentsname}{\centerline {\normalsize\bfseries Table of Contents}}
\newtocstyle[standard][leaders]{mytocstyle}{\settocfeature[1]{entryhook}{\normalfont\bfseries}}
\usepackage[capposition=top]{floatrow}
\usepackage{listings}
\usepackage{cite}
\usepackage{esvect}
\usepackage{footnote}
\usetocstyle{mytocstyle}
\usepackage{sectsty}
\sectionfont{\normalsize\centering}
\subsectionfont{\normalsize}
\usepackage{enumitem}
\renewcommand{\thesection}{}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}}
\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{algpascal}
\usepackage{algc}
\usepackage{graphicx}
\usepackage{times}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{balance}
\usepackage{multirow}
\usepackage{epstopdf}
\usepackage{threeparttable}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{color}
\usepackage{xcolor}
%\usepackage{algorithm}
%\usepackage{algorithmic}
\graphicspath{ {images/} }
\usepackage{graphicx}
\usepackage{comment}
\usepackage{times}
\usepackage{cite}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newenvironment{alginc}[1][pseudocode]{\medskip\algsetlanguage{#1}\begin{algorithmic}[1]}{\end{algorithmic}\medskip}
\newcommand{\Exp}{Exponential }
\newcommand{\G}{\mathbb{G}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\PP}{Pairing }
\newcommand{\Gone}{\mathbb{G}_1}
\newcommand{\Gtwo}{\mathbb{G}_2}
\newcommand{\Gthree}{\mathbb{G}_3}
\newcommand{\Gt}{\mathbb{G}_T}
\newcommand{\PPo}{Pairing}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclareMathOperator*{\argminA}{arg\,min} % Jan Hlavacek
\DeclareMathOperator*{\argminB}{argmin}   % Jan Hlavacek
\DeclareMathOperator*{\argminC}{\arg\min}   % rbp
\DeclareMathOperator*{\argmax}{argmax} 

\definecolor{lightgray}{rgb}{.9,.9,.9}
\definecolor{darkgray}{rgb}{.4,.4,.4}
\definecolor{purple}{rgb}{0.65, 0.12, 0.82}

\newtheorem{innercustomdfn}{Definition}
\newenvironment{customdfn}[1]
  {\renewcommand\theinnercustomdfn{#1}\innercustomdfn}
  {\endinnercustomdfn}

\lstdefinelanguage{JavaScript}{
    keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break},
    keywordstyle=\color{blue}\bfseries,
    ndkeywords={class, export, boolean, throw, implements, import, this},
    %ndkeywordstyle=\color{darkgray}\bfseries,
    ndkeywordstyle=\color{green}\bfseries,
    identifierstyle=\color{black},
    sensitive=false,
    comment=[l]{//},
    morecomment=[s]{/*}{*/},
    commentstyle=\color{purple}\ttfamily,
    stringstyle=\color{blue}\ttfamily,
    morestring=[s]{`}{'},
%    morestring=[b]"
}

\lstset{
    language=JavaScript,
    backgroundcolor=\color{lightgray},
    extendedchars=true,
    basicstyle=\footnotesize\ttfamily,
    %basicstyle=\footnotesize\sffamily,
    showstringspaces=false,
    showspaces=false,
%    numbers=left,
%    numberstyle=\footnotesize,
%    numbersep=9pt,
    tabsize=2,
    breaklines=true,
    showtabs=false,
    captionpos=b
    emph={= },
    emphstyle=\color{green}
}

\lstset{
    language=JavaScript,
    backgroundcolor=\color{lightgray},
    extendedchars=true,
    basicstyle=\footnotesize\ttfamily,
    %basicstyle=\footnotesize\sffamily,
    showstringspaces=false,
    showspaces=false,
%    numbers=left,
%    numberstyle=\footnotesize,
%    numbersep=9pt,
    tabsize=2,
    breaklines=true,
    showtabs=false,
    captionpos=b
    emph={= },
    emphstyle=\color{green}
}

\colorlet{punct}{red!60!black}
\definecolor{background}{HTML}{EEEEEE}
\definecolor{delim}{RGB}{20,105,176}
\colorlet{numb}{magenta!60!black}

\lstdefinelanguage{json}{
    basicstyle=\normalfont\ttfamily,
    numbers=left,
    numberstyle=\scriptsize,
    stepnumber=1,
    numbersep=8pt,
    showstringspaces=false,
    breaklines=true,
    frame=lines,
    backgroundcolor=\color{background},
    literate=
     *{0}{{{\color{numb}0}}}{1}
      {1}{{{\color{numb}1}}}{1}
      {2}{{{\color{numb}2}}}{1}
      {3}{{{\color{numb}3}}}{1}
      {4}{{{\color{numb}4}}}{1}
      {5}{{{\color{numb}5}}}{1}
      {6}{{{\color{numb}6}}}{1}
      {7}{{{\color{numb}7}}}{1}
      {8}{{{\color{numb}8}}}{1}
      {9}{{{\color{numb}9}}}{1}
      {:}{{{\color{punct}{:}}}}{1}
      {,}{{{\color{punct}{,}}}}{1}
      {\{}{{{\color{delim}{\{}}}}{1}
      {\}}{{{\color{delim}{\}}}}}{1}
      {[}{{{\color{delim}{[}}}}{1}
      {]}{{{\color{delim}{]}}}}{1},
}

\usepackage[colorlinks=true,linkcolor=black,citecolor=red,urlcolor=red,plainpages=false,pdfpagelabels=true, bookmarks=false]{hyperref}
\begin{document}
   \author{{\normalsize Yinhao Xiao}}
   \title{\Large{\bf Security and Privacy of Smart Devices} \\ \large Dissertation Proposal}
   \date{}
   \maketitle
   \thispagestyle{empty}
   \begin{center}
       B.S. in Information and Computing Science,\\ May 2012, Guangdong University of Technology \\
       M.A. in Mathematics,\\ May 2014, The George Washington University \\
       M.S. in Computer Science,\\ Dec 2015, The George Washington University \\[\baselineskip]
       
       A Dissertation Proposal submitted to\\
       The Faculty of\\The School of Engineering and Applied Science\\ of The George
       Washington University\\ in partial satisfaction of the requirements\\ for the degree
       of Doctor of Philosophy\\[\baselineskip]
       xxx, 2018\\[\baselineskip]
       Dissertation directed by\\[\baselineskip]
       Xiuzhen Cheng\\Professor of Computer Science
   \end{center}
   % display page numbers in the footer and centered. Start with roman numerals %
   \pagestyle{plain}
   \setcounter{page}{1}
   \pagenumbering{roman}


   \newpage
   \doublespacing
   \begin{center}
   {\Large{\bf Security and Privacy of Smart Devices}\\ \large Dissertation Proposal}\\[\baselineskip]
   {\normalsize Yinhao Xiao}
   \end{center}
   \noindent Dissertation Proposal Committee:\\

   \hfill\begin{minipage}{5in}
   {Xiuzhen Cheng, Professor of Computer Science, Dissertation
       Director}\\[\baselineskip]
   {Xiang Chen, Assistant Professor of Computer Engineering, Committee Member}\\[\baselineskip]
   {Timothy Wood, Associate Professor of Computer Science, Committee Member}\\[\baselineskip]
   {Arkady Yerukhimovich, Assistant Professor of Computer Science, Committee Member}\\[\baselineskip]
   
   \end{minipage}

   \newpage
      \section{Abstract}
   xxx
   
      \newpage

   \newgeometry{top=1in, bottom=1in, left=1.125in, right=1.125in}
   \tableofcontents
   \restoregeometry
   \newpage


   \cleardoublepage
   \phantomsection \label{listoffig}
   \addcontentsline{toc}{section}{\hspace{1.5pt} List of Figures}
   \begin{center}
       \listoffigures
   \end{center}
   \newpage


   \newpage
   \setcounter{page}{1}
   \setcounter{section}{1}
   \pagenumbering{arabic}
   \begin{singlespace}
       \section{Introduction}
   \end{singlespace}
   \setcounter{section}{1}
   \doublespacing
Smart devices refer to the electronic devices that are connected to the cloud or edge servers or with each other through different wireless protocols (e.g., Wi-Fi, 4/5G, Zigbee, Bluetooth, Software-Defined Radio, RFID, etc) in order to complete ubiquitous ``smart'' tasks such as sensing, controlling, actuating, messaging, or even decision making. Smart devices can mainly be taxonomized into two categories: smart mobile devices (i.e., smartphones and tablets), and smart home devices (e.g., smart thermostats, smart light, smart switch, and smart speakers). According to market research conducted by Statista, the total revenue of the smart devices in the US has reached 79.8 billion dollars by the year 2018~\cite{Statista:smarthome}\cite{statista:smartphone}. It is also projected that the average number of networked smart devices per person can reach 13 by the year of 2021~\cite{smartdeviceperperson}.

With the presence of the prevailing performance with respect to market sharing, as shown above, one may raise a question: If security vulnerabilities of smart devices and their corresponding systems are discovered by vicious personnel who later exploits these vulnerabilities to conduct malicious activities, are the consequences more serious than the ones of traditional computer or Internet infrastructure? Unfortunately, the answer is positive for this question due to the following two reasons:
\begin{itemize}
\item Smart devices tend to reflect more personal information than the tradition computers do. For example, using smartphones to take pictures has become the main way of photo-taking\cite{smartphonephoto}. Hence, the smartphone is the major source to store a user's personal photos. It is not difficult to envision the devastating consequence if an attacker can access the resources in a smartphone without authorization through security breaches.

\item Smart devices are interconnected tightly for better functioning and automation (e.g., a smart home system). The security drawback of the design allows an attacker to take down the whole system more quickly and effectively by compromising a single device, to begin with. A notable example is the Mirai virus which managed to infect 200,000 -
300,000 IoT smart devices in the first 20 hours~\cite{antonakakis2018mirai}.
\end{itemize}

Even though defending smart devices against malicious exploits and attacks is urgent and critical, securing them is more challenging than securing traditional computers not only because they are computationally limited to empower high-end firewalls, but are highly heterogeneous both on the hardware level and firmware level. Having observed the situation,  we mainly focus on identifying vulnerabilities, inventing attacks, and developing corresponding defensive mechanisms for smart devices. In this proposal, we specifically target the security of smartphones and their corresponding systems. In the following contexts, we focus on two main directions of studying the security and privacy of smartphones, i.e., from the perspective of system design flaw and from the perspective of side-channel information exploit. For the system design flaw, we mainly present an OS-Level logic flaw existing in Android Task Mechanism that results in severe privilege leakage, through which we implemented four proof-of-concept attacks. Lastly, we developed an efficient scanner to help users to avoid the attacks. For the side-channel information exploit, we mainly present a novel attack vector which effectively associates the user's identity in social networks with the smartphone device using Android side-channel information. 

\subsection{Exploiting Android Task Mechanism}
The Android system's security is based on several layers of security
mechanisms. In particular, each app is assigned a set of permissions and is only allowed to access system resources and services within the
permissions given. In addition, to prevent apps from accessing
information of others, each app is confined into its own partition.
It is enforced using the process isolation and user-based protection
mechanisms provided by Linux, where each app is assigned to a unique
Linux user ID.

Strong isolation increases the bar for attackers to carry out
malicious activities, but it also hinders benign apps from
communicating and collaborating with one another. To facilitate apps
collaboration in a complex task, Android allows isolated apps to
communicate through explicit interfaces, such as the Intent
mechanism. For example, Instagram uses intents to access the Single
Sign-On (SSO) service of Facebook to authenticate users.  Furthermore,
Android provides the Android Task Structure mechanism to allow activities
from different apps to be seamlessly integrated into a task, giving
them the convenience when accessing common information. For example,
when Instagram uses the Facebook API for the authentication service
provided by Facebook, users can navigate through activities Instagram
app and Facebook app as if they are the same app.

Though the mechanisms are designed for facilitating app communication
and collaboration, relaxing the isolation provided by the Android
system often causes over-permissive privilege to apps. 
As the task mechanism of Android is developed to facilitate inter-app
collaboration, apps in a task may get additional privilege beyond what
is allowed by the isolation-based Android security
mechanism. Demonstrated by recent exploits~\cite{TaskHijacking}, a
malicious app can hijack the task mechanism for attacks such as
spoofing and phishing. The privilege obtained by apps in the same task
is well beyond that for collaboration, effectively making the Android
task mechanism a form of authorization.

In this work, we conduct an analysis of the security of the Android
task mechanism. First, we analyze possible ways that an app can join a task
and the privilege ``leaked'' to other apps in the same
task. Specifically, to explore the ways Android controls tasks, we
dynamically probe possible combinations of the flags and system states
that can affect an app's task status.  We also analyze the additional
privilege that can be obtained by an app when it joins a task. Second, built on the understanding of the task control mechanism and task privileges, we identify end-to-end attacks that steal information from other apps. In particular, we identified four proof-of-concept attacks based on exploiting the task mechanisms. The attacks include
UI phishing, screenshot based password stealing, activity-in-the-middle
activity, and gallery stealing. All of them only require common
permissions, e.g., \texttt{INTERNET} and \texttt{READ\_EXTERNAL\_STROAGE}. Compared to
the attacks by existing exploits, we have identified new attack
mechanisms that can {\em actively} interfere with benign apps. The
short video demos can be found in~\cite{demo}. Finally, to prevent attackers from misusing the task mechanism, we develop an efficient scanner that can help users to
identify the risks related to Android tasks.

The details of this work is presented in Section~\ref{sec:atmtitle}. 

\subsection{Device-Identity Association Attack Using Android Side-Channel Information}
Online social networks such as Twitter and Flickr revolutionize the ways people interact with each other. More and more users begin to access social networks through mobile devices, making it completely possible to de-anonymize a target individual based on the side-channel information from his mobile device due to the rich features generated by the user's device while operating on social network apps. We call this kind of attack \emph{device-identity association}. Though it is relatively difficult for an attacker to trick users into installing a malware with strong permissions, recent research shows that public information obtained from the Android system without permission can be used to link to a user's identity \cite{zhou2013identity}. Nevertheless, the attack method proposed in \cite{zhou2013identity} by observing the fixed TCP payload sequence pattern is no longer effective due to the recent updates of the social network apps. We manually monitored the Twitter app's TCP sequence while tweeting and found that the sequence was irregular and noisy. Then we used Frida, an injection framework~\cite{frida}, to trace the function calls of the Twitter app, and found that the root cause lies in that the Twitter app no longer handles each tweeting event in a separate TLS session (separate calls to the \texttt{url.openConnection()} function), but rather combining them into one TLS session (only one call to the \texttt{url.openConnection()} function).

We also observed that the attack based solely on the mobile device side-channels faces challenges due to limited information from one social network app. Nevertheless, in practice, the majority of social network users access their accounts very infrequently, according to our study on 500,008 Twitter accounts); and a user typically has accounts in different social networks such as Twitter, Flickr, and Instagram; furthermore, the social network accounts of the same user are often highly similar/correlated in their user profiles, e.g., user name, picture, and locations. Such facts reveal a high potential of device-identity association based on account correlations. 

The objective of this work is to investigate efficient and effective techniques to accurately identify a target user (more precisely, the social network accounts of the user) in social networks even though the information obtained by an attacker is limited. 
In order to accomplish this goal, we proposed a novel attack architecture with two attack vectors, correlation from device system states to a social network (DS-SN) and correlation for cross social networks (SN-SN). For the DS-SN attack, we studied the association between a user's identity in a social network and the user's device system states, e.g., memory and network data. In our threat model, an attacker can get information from the system level of a user's smartphone through installed apps without any permission or the user's consent. Leveraging these states, the attacker can infer the system events, e.g., activity transitions and keyboard status, which can be used to further infer the user's social network events, e.g., sending tweets and posting Instagram photos at certain timestamps. The attacker then collects and aggregates these social network events to identify the target user's identity in the social network. However, DS-SN is sometimes not enough to identify a user's identity due to limited social network events the user leaves in a single social network; therefore, we proposed the idea of SN-SN attack, which exploits the cross social network similarity to allow the attacker to efficiently and accurately figure out the identities of a user through the system and network state left by the user's activities and account profiles on the social networks. 

The details of this work is presented in Section~\ref{sec:dssnassociate}. 


   \newpage
      \begin{singlespace}
           \section{Preliminaries}
      \end{singlespace}
   \label{sec:preliminaries}
\subsection{Android Security Basis and Android Task Mechanism}
Components in Android include {\em Activity}, {\em Service}, {\em
  Content Provider}, and {\em Broadcast Receiver}. An activity,
representing a single screen with user interface, is the most basic
elements in Android OS. A service in Android is a UI-less component
running in the background. A content provider supplies data from one
application to another through methods of the \texttt{ContentResolver}
class with the ways of storing data in databases, in files, or over
the network. A broadcast receiver responds to broadcast messages from
other applications.

Android adopts several layers of isolation and sandboxing mechanism as
its basic mechanism of security. In particular, it defines a set of
permissions to control the access of apps. Apps can access specific
resources only if they are granted with required permission.  In
addition, Android uses user-based protection of Linux to isolate
apps. It allocates a unique Linux user ID to each app, which naturally
isolates the app from others using the process-based isolation
mechanism provided by the Linux kernel.

The Android task mechanism is designed for facilitate inter-app
communication and for better support app collaborating under same
tasks. It allows activities from different apps can reside in the same
task to perform communications more conveniently~\cite{taskdoc}.  As
an example, when the user clicks a ``feedback'' button from an
activity of a game app, Android starts the composer activity of an
email app, and puts it onto the game app's activity.  After the user
finishes sending email, the composer activity is put off and the game
app returns to the top.  In such a way, two activities are organized
to finish a task, while they are actually from different apps.


The Android task mechanism is affected by several flags of apps. The
following are the key attributes affecting how apps are grouped.

\textbf{launchMode:} This is the attribute which decides how an activity
will be launched. It has four values, i.e., \textit{standard},
\textit{singleTop}, \textit{singleTask} and
\textit{singleInstance}. Activities with \textit{standard} or
\textit{singleTop} can be instantiated multiple times while activities
with \textit{singleTask} or \textit{singleInstance} can only begin a
task and be the root of the task. Moreover, \textit{singleInstance}
does not permit other activities to be part of its task. An
activity without \textit{launchMode} specifically set is
assumed to be \textit{standard} by default.

\textbf{taskAffinity:} Activities with the same \textit{taskAffinity},
normally the name of the package, conceptually are in the same task,
but this is not always the case. We refer to
Section~\ref{sec:atmapproach} and Table~\ref{tbl:taskinterference} for
more details. An activity without this attribute set is assumed to
have the same \textit{taskAffinity} as its own package name.

\textbf{allowTaskReparenting:} This is a boolean attribute indicating
whether an activity can be moved to the task which has the same
\textit{taskAffinity} from the original task it is started. An
activity without this attribute specifically set is assumed to be
\emph{allowTaskReparenting=false}.

For better demonstration, consider the example where an app has the
functionalities of viewing contacts as well as sending emails to
contacts. The app has two activities for these two functionalities,
\textit{SendEmailActivity} and \textit{ViewContactActivity}. For
better IPC and logic concerns, designers of the app set the
\textit{taskAffinity} of \textit{SendEmailActivity} to be the same as
the system email app, the \textit{taskAffinity} of
\textit{ViewContactActivity} to be the same as system contact app and
\textit{allowTaskReparenting} to be true for both activities.

\subsection{Publicly Available System States in Android}
In this subsection, we present the publicly available side-channel state information in Android that are exploited by our proposed inference attacks detailed in Section~\ref{sec:dssnassociate}. We focus on three common channels of public information, namely memory, CPU, and network.

\subsubsection{Memory}
The Android system leverages Android Runtime (ART) or its predecessor, Dalvik Virtual Machine (DVM), as the runtime environment to execute binaries in the Dalvik Executable (DEX) format. Both ART and DVM use the paging and memory-mapping mechanisms \cite{androidmemoverview} to manage memory allocation of apps. Particularly, Android maintains four types of memory data for each process running on the system: \texttt{Virtual Set Size} (\emph{VSS}), \texttt{Resident Set Size} (\emph{RSS}), \texttt{Proportional Set Size} (\emph{PSS}), and \texttt{Unique Set Size} (\emph{USS}), which are listed in Table~\ref{tab:memory}.

\begin{table}[h]
\centering
    \caption{Memory Size Information}
\begin{tabular}{|l|p{4.5cm}|}
    \hline\hline 
    \textbf{Type of Memory Size} & \textbf{Description} \\ 
    \hline\hline 
    \small Virtual Set Size (VSS) & \small Total virtual memory of a process \\ 
    \hline 
    \small Resident Set Size (RSS) & \small Total physical memory of a process \\ 
    \hline 
    \small Proportional Set Size (PSS) & \small Memory shared between a process and other processes \\ 
    \hline 
    \small Unique Set Size (USS) & \small  The set of pages unique to a process\\ 
    \hline 

\end{tabular} 
        \label{tab:memory}
\end{table}

Android does not treat memory information as sensitive
system data. Consequently, an app can obtain other apps' memory
information without requesting any permission. There are four methods to retrieve
the memory data of an app, which are listed below:
%
\begin{itemize}
\item The Android API has a standard class \texttt{Debug.MemoryInfo},
  which provides complete interfaces to query the information for
  a process~\cite{apimem}, including private dirty pages, shared dirty
  pages, and the PSS for Dalvik.
\item The \texttt{/proc} file system has \texttt{/proc/pid/statm}
  (\texttt{pid} is the id of the process) that lists all four types of
  memory information: \emph{VSS}, \emph{USS}, \emph{RSS}, and \emph{PSS}.
\item The commands ``\texttt{top}'' and ``\texttt{ps}'' in Android
  Toolbox~\cite{toolbox} yield \emph{VSS} and \emph{RSS} for any given
  process. These commands also use information from the \texttt{/proc}
  file system.
\item In some devices, \texttt{/system/xbin/procrank} is provided.
  The command \texttt{procrank} yields all four types of memory
  information for all processes in real time.
\end{itemize}

\subsubsection{CPU Usage}
Android maintains three types of CPU usage data for a process, which are publicly available:
%
\begin{itemize}
\item CPU usage rate: the total percentage of time a
  CPU operates on a running process, with 100\% indicating that for a given period,
  the CPU spends all its available cycles running the specific process.

\item User time (\texttt{utime}): the CPU time spent in the user code of a process, measured in clock ticks.

\item System time (\texttt{stime}): the CPU time spent in the system code (which is
  the kernel) of a process, measured in clock ticks.

\end{itemize}

A zero-permission app can retrieve the CPU usage data of
another app by either (1) accessing \texttt{/proc/pid/stat} which lists
\textit{user time}, \textit{system time}, and other time-related information; or
(2) using commands ``\texttt{top}'' and ``\texttt{ps}'' with Android
Toolbox to return the user time, system time, and CPU usage percentage
of any given process.

\subsubsection{Network}
Android does not store the contents of TCP packets of any
process; but it maintains a record of the number of bytes sent and received through TCP connections by a process. This information is available to any
zero-permission app, and can be obtained by the following
ways:
\begin{itemize}
\item The \texttt{TrafficStats} from Android API has the method
  \texttt{getUidRxBytes(int uid)}, which returns the received bytes for a
  given user ID \texttt{uid}.

\item The \texttt{/proc} system files
  \texttt{/proc/uid\_stat/pid/tcp\_snd} and \\
  \texttt{/proc/uid\_stat/pid/tcp\_rcv} respectively maintain the bytes sent and
  received for an app.
\end{itemize}



   \newpage
   \begin{singlespace}
   \section{Privilege Leakage and Information Stealing through the Android Task Mechanism}
   \end{singlespace}
    \label{sec:atmtitle}



%===============================================================================

\subsection{Threate Model and Approach Overview} \label{sec:threatandapproach}

In this subsection, we present the threat model and the overview of our attack approach.

\subsubsection{Threat Model} \label{subsec:threat}

To study the security of the Android task mechanism, we consider a
scenario as follows. There are two apps, i.e., AppB and AppM,
installed in the same Android device, where AppB is benign and AppM is
developed by attackers.  We assume AppM does not have to require any
permission to manipulate tasks. However, we assume AppM can be granted
permissions for following-up behaviors, such as sending the retrieved
information out or accessing local storage.

\begin{figure*}[t]
        \centering
        \includegraphics[width=1\linewidth]{overall.pdf}
        \caption{Approach Overview}
        \label{fig:arch}
\end{figure*}

\subsubsection{Approach Overview} \label{sec:approachoverview}

The goal of our work is to comprehensively analyze the Android task
mechanism to identify attacks, as well as creating solutions to
prevent such attacks.

As shown in Figure~\ref{fig:arch}, our research consists of four
components: \textsl{Understanding Task Control}, \textsl{Understanding
  Task Privilege}, \textsl{Exploitation Analysis} and \textsl{Task
  Interference Checking}.

The first component is to analyze the Android task mechanism,
identifying control conditions that can be leveraged by attackers.
We aim to find out the interference of tasks between two
apps, and identify the dominating factors deciding the apps'
property.  Secondly, we focus on studying the additional privilege
apps obtained when two apps are in the same task. We delicately test sensitive
system APIs and compare the difference of the results before and after
apps in the same task. Based on the understanding from the previous
stages, to demonstrate the achievability and severity of the
privilege escalation against Android task mechanism, we develop four light-weight
real-world attacks that can steal the sensitive information
successfully, most of which only requires \texttt{INTERNET}
permission.  At last, we design a task interference checking app to
detect the task interference between users' important apps and other
installed apps.

\subsection{Security Analysis of Android Task Structure}\label{sec:atmapproach}
In this subsection, we introduce our approach. We focus on two aspects of
the Android task mechanism. First, We analyze the conditions that
affect Android task control to identify different ways that can
include an app into a task. Second, we explore the privilege an app
can get when it is included into a task. These are two necessary
components to identify new attacks.


\subsubsection{Understanding Android Task Control Conditions}

We explore the conditions and actions of Android task control through
dynamic testing.  To do this, we examine the Android
documentation~\cite{taskdoc} to create test cases to drive the
exploration. Our goal is to check the influence of the flags
introduced in Section~\ref{sec:preliminaries} on the task mechanism.

{\noindent \bf Testing Methodology.} We implemented the two template
apps introduced in Section~\ref{sec:threatandapproach}, AppB and AppM, as the
inputs to drive the testing process.  For each combination of the
task-control-related flags, such as {\em launchMode} and {\em
  taskAffinity}, we set the corresponding value in app templates,
create a pair of AppB and AppM, and test them with different sequences
of launching events, e.g., using the Android Launcher to start AppB
(denoted as Launcher$\rightarrow$AppB) or using AppB to launch AppM
(denoted as AppB$\rightarrow$AppM). During our test, AppB's {\em
  taskAffinity} is set to ``TaskB''.  We only test the conditions
where AppM's {\em allowTaskReparenting} is set to ``true'', as a
``false'' value in this flag will not result in task interference.

The results are summarized in Table~\ref{tbl:taskinterference}.  We
are interested in cases with potential task interference, i.e., AppM
ends up running as part of TaskB.  We mark the cases for task
interference, i.e., AppM running as part of TaskB, with an asterisk
``*''. The cases without an asterisk attached are considered to be
safe. We list four identified dangerous cases below.

\begin{itemize}
  \item {\bf Case 2}. Under the conditions of this case, AppM is
    launched first by the Android Launcher, followed by AppB. Only
    AppM runs at the foreground, while AppB cannot be executed.

    In this case, AppM blocks AppB from execution, which is a case
    of denial-of-use to AppB.
  \item {\bf Case 4}. Under the conditions of this case, AppM is
    launched by the Android Launcher, followed by AppB. AppB runs in
    the foreground, and AppM runs in the background, both in TaskB.
  \item {\bf Case 9}. Under the conditions of this case, the Android
    Launcher starts AppM. AppM then starts AppB. AppB runs in
    the foreground, and AppM runs in the background, both in TaskB.
  \item {\bf Case 10}. Under the conditions of this case, the Android
    Launcher starts AppB. AppB then starts AppM. AppM runs in
    the foreground, and AppB runs in the background, both in TaskB.
\end{itemize}

Whether two Apps are in the same task can be determined by
viewing the \emph{Recents} screen which renders all processes that
were opened since last clearance\cite{recents}. \emph{Recents} screen
is rendered when a user presses the \emph{Recents} button which is
located at the third from left to right at the button bar followed by
\emph{Back} and \emph{Home} buttons. If two Apps are in the same task,
\emph{Recents} screen will only show one process other than two when
they do not reside in the same task. Note that according to our
experiment, flags such as \texttt{FLAG\_ACTIVITY\_CLEAR\_TOP} and
\texttt{FLAG\_ACTIVITY\_REORDER\_TO\_FRONT} do not pose a difference
than the \texttt{SIGLE\_TOP} in our case. Therefore, we only include
the \texttt{SINGLE\_TOP} flag in our Table~\ref{tbl:taskinterference}.

\begin{table*}
\scriptsize
\centering
\caption{Task Interference Table. We assume AppB is running with the
  task ``TaskB.'' In the events, the operation A$\rightarrow$B stands
  for A launches B. In the resulting state's status, F stands for
  execution in foreground; B stands for execution in background; X
  stands for not-running.}
\label{tbl:taskinterference}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{|l|c|c|c|c|c|c|c|c|}
\hline
\textbf{Case \#}                              &
\multicolumn{4}{c|}{\textbf{Initial Conditions}}         &
\textbf{Events} &
\multicolumn{3}{c|}{\textbf{Resulting State}}           \\
\cline{2-5} \cline{7-9}
& AppB & \multicolumn{3}{c|}{AppM} & &
AppB &  \multicolumn{2}{c|}{AppM} \\
\cline{2-5} \cline{7-9}
& LaunchMode & LaunchMode & TaskAffinity & Reparenting &  & Status &
Status & Task\\
\hline \hline
1  &  standard or & standard or & TaskB  & True
   & Launcher$\rightarrow$AppB; Launcher$\rightarrow$AppM    & F & X & - \\

   &  singleTop or & singleTop or &        &
   &                                   &   &   &  \\

   & flag(SINGLE\_TOP) & flag(SINGLE\_TOP) & &
   &                                   &   &   &  \\
\hline
2  &  standard or & standard or & TaskB  & True
   & Launcher$\rightarrow$AppM; Launcher$\rightarrow$AppB    & X & F & TaskB \\

*  &  singleTop or & singleTop or &        &
   &                                   &   &   &  \\

   & flag(SINGLE\_TOP) & flag(SINGLE\_TOP) & &
   &                                   &   &   &  \\
\hline
3  &  singleTask or & standard or & TaskB  & True
   & Launcher$\rightarrow$AppB; Launcher$\rightarrow$AppM    & F & X & - \\

   & flag(NEW\_TASK) & singleTop or & &
   &                                   &   &   &  \\

   &                 & flag(SINGLE\_TOP) & &
   &                                   &   &   &  \\

\hline
4  &  singleTask or & standard or & TaskB  & True
   & Launcher$\rightarrow$AppM; Launcher$\rightarrow$AppB    & F & B & TaskB \\

*  & flag(NEW\_TASK) & singleTop or & &
   &                                   &   &   &  \\

   &                 & flag(SINGLE\_TOP) & &
   &                                   &   &   &  \\

\hline
5  &  singleTask or & singleTask or & TaskB  & True
   & Launcher$\rightarrow$AppB; Launcher$\rightarrow$ AppM     & B & F & TaskM \\

   & flag(NEW\_TASK) & flag(NEW\_TASK) & &
   &                                   &   &   &  \\
\hline

6  &  singleTask or & singleTask or & TaskB  & True
   & Launcher$\rightarrow$ AppM ; Launcher$\rightarrow$AppB    & F & B & TaskM \\

   & flag(NEW\_TASK) & flag(NEW\_TASK) & &
   &                                   &   &   &  \\
\hline

7  &  singleInstance or & any or & TaskB  & True
   & Launcher$\rightarrow$AppB; Launcher$\rightarrow$AppM    & F & X & - \\
\hline

8  &  singleInstance or & any or & TaskB  & True
   & Launcher$\rightarrow$AppM; Launcher$\rightarrow$AppB    & F & B & TaskM \\
\hline

9  &  standard or & standard or & TaskB  & True
   & Launcher$\rightarrow$AppM; AppM$\rightarrow$AppB  & F & B & TaskB \\

*   &  singleTop or & singleTop or &        &
   &                                   &   &   &  \\

   & flag(SINGLE\_TOP) & flag(SINGLE\_TOP) & &
   &                                   &   &   &  \\
\hline

10  &  standard or & standard or & TaskB  & True
   & Launcher$\rightarrow$AppB; AppB$\rightarrow$AppM  & B & F & TaskB \\

*   &  singleTop or & singleTop or &        &
   &                                   &   &   &  \\

   & flag(SINGLE\_TOP) & flag(SINGLE\_TOP) & &
   &                                   &   &   &  \\
\hline
\end{tabular}
}
\end{table*}

\subsubsection{Understanding Privilege Obtained in the Same Task}
\label{sec:priv}

From the results in Table~\ref{tbl:taskinterference}, we can see that
AppM has several ways to be included into the task of AppB, often
without involving actions from other apps or the system. Next, we
explore the privilege obtained through the Task mechanism, including
privilege for retrieving other apps' information and privilege for
changing other apps' states. Therefore, if the privilege given to apps
in the same task allows them to carry out dangerous actions, it can be
potentially misused by the malicious app.

\textbf{Retrieving Information of Other Apps}

\noindent

Figuring out the execution state of a victim app, such as whether it
is running and which activity is in foreground, is often used as the
first step in several attacks, such as UI
hijacking~\cite{UIstateinference}. Therefore, Android by default disallows one app
from directly querying another app's runtime information from through
the Android sandbox policy.

In older versions of Android, there were APIs allowing inter-app
runtime information checking.
For devices that are prior to \textit{Android Lollipop
  (v5.0)}, directly calling the API
\texttt{getRunningTasks(int maxNum)} will return the information of as
many as \texttt{maxNum} running activities~\cite{getrunningtask}.
However, this function is deprecated after \textit{Lollipop} since allowing third-party apps to invoke the function
directly will cause information leakage in important apps.

For devices prior to \textit{Android MarshMallow (v6.0)}, directly
calling \\
\texttt{getRunningAppProcesses()} returns a list of
application processes that are running on the
device~\cite{getrunningtask}. This function returns a
\textit{RunningAppProcessInfo} object, which includes a member
variable called \textit{importance} that represents the importance
level that the system places on the
process~\cite{processimportance}. It has one of these values:
\texttt{IMPORTANCE\_FOREGROUND}, \texttt{IMPORTANCE\_VISIBLE},
\texttt{IMPORTANCE\_SERVICE}, \texttt{IMPORTANCE\_BACKGROUND} and
\texttt{IMPORTANCE\_EMPTY}. If \textit{importance} is
\texttt{IMPORTANCE\_FOREGROUND}, the corresponding process is running
in the foreground. This method, however, cannot accurately point out
which activity running in the foreground since it operates on a
process level and accesses only the package name.  This method is also
no longer supported for \textit{MarshMallow} devices with API level 23
unless the third-party app who is making a call to this function has
the same process ID as the target process.


\paragraph*{Getting App Running Information in a Task.}
Although the Android API \\
\texttt{getRunningTasks()} is deprecated for
direct usage, we have found that it still works if the calling app and
the target app are in the same task.  The official documentation of
\texttt{getRunningTasks()} does not explicitly point it out but only
states that if it is called, this function only returns a small
subsets of information, e.g., the information of the caller's own task
and home task which is considered to be not
sensitive~\cite{getrunningtask}.


\textbf{Changing States of Other Apps}

\noindent

\paragraph*{UI Injection.}
Ideally, if an app is running in the foreground, other apps isolated
from this app should not perform sensitive operations on it. Chen {\em et
al.}~\cite{UIstateinference} show two UI-injection methods that do not
require any permissions: (1) starting an \texttt{Activity} by setting
\texttt{lauchMode=singleInstance}. This is also how most system apps,
such as the alarm app, pop up a window on the top of another
app~\cite{androidlaunchmode}; (2) starting an \texttt{Activity} from
the Android broadcast receiver~\cite{androidbroadcastreceiver}.

In our analysis, we find that if two apps are in the same task, the
UI-injection attack becomes easier.  The attacker can simply call the
function \texttt{startActivity()} to achieve the same effect. Through
understanding the Android SDK source code, \texttt{startActivity()}
invokes \texttt{startActivityForResult()} with
\texttt{requestCode=-1}. Later \\
\texttt{startActivityForResult()}
invokes \texttt{execStartActivity()} in the Instrumentation class, a
base class for implementing application instrumentation
code~\cite{Instrumentation}. \\
 \texttt{execStartActivity()} then checks
the base package of the calling activity by invoking
\texttt{getBasePackageName()}. If the base package of calling activity
matches with that of target activity, the Android system launches the
target activity.

\paragraph*{Terminating UI.}
Android does not allow a third-party app to terminate a running app
unless they are in the same process. Although an app is not in the
foreground, the Android system still allows any third-party apps to
make calls to
\texttt{killBackgroundProcesses()}~\cite{killBackgroundProcesses} to
terminate any specific background app. There is no direct way to
terminate a foreground-running activity.

Unlike \texttt{startActivity()}, even if two apps are in the same
task, calling \texttt{finish()} or \texttt{finishActivity()} will not
terminate the foreground activity, but will terminate the activity
that makes the call. However, we found that as long as two apps are in
the same task, calling the API \texttt{finishAndRemoveTask()} results
in terminating the whole Task regardless of whether an activity is
running in the foreground~\cite{finishAndRemoveTask} or not.
This provides the malicious app an interface to terminate other apps which are within the same task as it.

\subsection{Information Stealing Attacks}\label{sec:infoattack}
Based on analysis from Section~\ref{sec:atmapproach}, we develop
four proof-of-concept attacks: \textsl{UI Phishing},
\textsl{Activity-in-the-middle Attack}, \textsl{Gallery Stealing}, and
\textsl{Screen Shot Capture}. These four attacks demonstrate the
severity of the security problems we identified. In this subsection, the
attacks are illustrated using two most popular social apps, Instagram
and Facebook. Except Gallery Stealing, which requires
\texttt{READ\_EXTERNAL\_STORAGE}, all other three attacks only require
the \texttt{INTERNET} permission~(in order to send out the information
stolen).

\subsubsection{UI Phishing}
UI Phishing is a popular type of attacks to spoof users.  The
difficulty of phishing attack is to decide the timing when the
spoofing interface should be prompted, in order to prevent the victim
from noticing it.  Ren {\em et al.}~\cite{TaskHijacking} introduced
``Back Hijacking'', which directs users to a spoofed bank
\textit{LoginActivity}. The key difference is that the attack method
identified in our approach {\em actively} interact with the victim app
using the privilege obtained through the approaches we discussed in
Section~\ref{sec:priv}.

Our proof-of-concept UI Phishing attack is implemented against
the scenario when a user logs in to Instagram using his/her Facebook
account.  In order to ease understanding the phishing attack against
this scenario, we brief the Facebook SSO service.  According to the
Facebook Android developer documentation~\cite{FacebookLoginWays},
Facebook SDK takes three ways for apps who require Facebook Login as
part of functionality:

\begin{itemize}
\item {\bf Native App Login.}
If the Android device already has the Facebook app installed, pressing
the Facebook login button directly opens the Facebook app where user
can log in his/her Facebook account and grants permission to the
third-party app to access his/her Facebook personal information.

\item \textbf{Chrome Custom Tab Login. }
If the Android device does not have the Facebook app installed, a
third-party app can ask the Chrome browser to open Facebook login page
by registering a scheme in the \texttt{Manifest} with the format
\texttt{fb+facebook\_app\_id}.

\item {\bf WebView Login.}
Finally if neither the Android device has Facebook app installed, nor
does the third-party app register for Chrome Custom Tab Login, an
embedded WebView will be launched dynamically rendering the content of
Facebook login page.
\end{itemize}

Our attack works when a user presses the ``Log in with Facebook''
button in Instagram. We assume that a user already has Facebook App
installed in the device. Instagram includes Facebook Login as a part
of its functionality. It does not register for Chrome Custom Tab
Login. In other words, after pressing the ``Log in with Facebook''
button in Instagram, it will launch Facebook App directly. The package
name of Facebook app is \texttt{"com.facebook.katana"}, the package
name of self-build WebView is \texttt{"com.android.webview"} and the
package name of Instagram is \\
\texttt{"com.instagram.android"}.  Shown
in Figure~\ref{fig:uiphishing}, it works in the following steps.

\begin{figure*}[t!]
        \centering
        \begin{subfigure}[t]{0.5\textwidth}
                \centering
                \includegraphics[width=\linewidth]{attack-phishing-0.pdf}
                \caption{Single-Sign-On Architecture}
          \end{subfigure}%
          %\quad
        \begin{subfigure}[t]{0.5\textwidth}
                \centering
                \includegraphics[width=\linewidth]{attack-phishing-1.pdf}
                \caption{UI Phishing Attack}
        \end{subfigure}
        \caption{UI Phishing.}
         \floatfoot{(a) When the user selects
          ''login with Facebook'' in Instagram, Instagram will launch
          the Facebook app. After the user inputs username, password
          and finishes the authentication with the Facebook service
          provider, Instagram gets the permission to access the user's
          Facebook resources. (b) The malicious app Mal\_App declares
          same taskAffinity as Instagram. Mal\_App creates a
          background thread and monitors the running states of
          Instagram. When the user selects Facebook login button and
          Instagram launches the Facebook activity, Mal\_App will
          override Facebook with a fake login UI. The
          username/password input by the user will be sent to
          Mal\_App's service provider.}
           \label{fig:uiphishing}
\end{figure*}



\textbf{(1)} Attacking app declares the same task as Instagram. This step
can be achieved by setting the attributes of \textit{taskAffinity} and
\textit{allowTaskReparenting} as follows.
\begin{lstlisting}[language=XML]
 <activity
            android:name=".UIPhishingActivity"
            android:allowTaskReparenting="true"
            android:taskAffinity="com.instagram.android">
\end{lstlisting}

\textbf{(2)} The launcher first launches the attacking app, which
launches Instagram immediately through invoking the task parent since
Instagram is the parent of the current task. Before Instagram's
\texttt{setContentView(R.layout.main)} function can be called, the
attacking app launches Launcher (Home), meaning that Instagram cannot
be displayed in order to achieve the stealthiness. The process can be completed in a fairly short time and will not be noticed by the victim with bare eyes. After that, our attacking app waits for victim to launch Instagram herself.


\textbf{(3)} The attacking app then creates a background thread which
runs in a cycle of, we devise, every 100 milliseconds. In the
meantime, it checks whether there is a change in the foreground
package name, i.e., in our case, the package name changes from \\
\texttt{"com.android.webview"} to \texttt{"com.facebook.katana"}. This
can be achieved by simply making API call to
\texttt{getRunningTasks()}. Once the foreground package has been
changed to Facebook, our attack pops up our counterfeit Facebook
\textit{LoginActivity} overriding the real one. The spoofed UI
collects the user's login information and send it to adversary's
back-end server.

\subsubsection{Activity-in-the-middle Attack}
The Facebook SSO process is based on OAuth
2.0~\cite{OAuthDemystified}. The main steps of this mechanism are: (1)
When the user opens the relying party (RP) app, in our case,
Instagram, it passes its \texttt{Facebook\_app\_id} and directed URL
to the Android System.  (2) The Android system then redirects user to
the Service Provider (SP), in our case, Facebook, and passes it the
\texttt{Facebook\_app\_id}.  (3) If the user requests to grant the
permission to the RP, SP will issue an access token to the Android
system.  (4) The Android system passes the access token to RP, by
which RP is able to access the user's protected resource on SP.

Facebook has two types of access tokens, short-term and
long-term~\cite{fbaccesstoken}. Short-term access token lasts several
hours and long-term lasts for 60 days. Unless specifically required,
Facebook usually issues short-term access token. RPs use graph API
provided by Facebook to retrieve protected resources hosted on
Facebook server~\cite{graphapi}. Graph API is an HTTP-based API, which
is implemented as the following URL:
 \begin{lstlisting}
 https://graph.facebook.com/me?fields=xxx&access_token=xxx
 \end{lstlisting}

In other words, any party who has the access token can access the
user's protected resources hosted on Facebook servers.

In Android, redirecting to the Facebook app is done by intent
transition based on \texttt{startActivityForResult()} and
\texttt{onActivityResult()}.  We implement an MITM attacking app whose
model runs in the following steps, shown in Figure~\ref{fig:mitm}.

\textbf{(1)} It follows the first three steps in the UI Phishing
attack model.

\textbf{(2)} Instead of popping up a phishing login
page like UI Phishing, the MITM attack pops up a transparent activity,
which blocks the traffic that is supposed to be relayed to Facebook
server from user's device system and passes our own traffic to
Facebook. This step can be easily realized by creating an invisible
Facebook Login Button and sending a button pressed event itself by
invoking \texttt{mFacebookLoginBtn.performClick()}.

\textbf{(3)} After the user grants the permission, which he/she
intends for Instagram, the MITM app retrieves the access token. Since
Instagram runs in the background, once the foreground finishes,
Instagram will be invoked.


\textbf{(4)} To finalize the process, the adversary needs to verify
\texttt{APP\_ID} and \emph{App Secret} with Facebook. An adversary can
either register its attacking app in Facebook Developer Website and
use its own \texttt{APP\_ID} and \emph{App Secret} or steal other RP
apps' ID and Secret. Facebook RP Apps will post an HTTP message when
user system launches native Facebook App.

\begin{figure*}[t]
        \centering
        \begin{subfigure}[t]{0.5\textwidth}
                \centering
                \includegraphics[width=\linewidth]{attack-mim-0.pdf}
                \caption{Single-Sign-On Permission Granting Architecture}
          \end{subfigure}%
          %\quad
       \begin{subfigure}[t]{0.5\textwidth}
                \centering
                \includegraphics[width=\linewidth]{attack-mim-1.pdf}
                \caption{Activity-in-the-Middle Attack}
        \end{subfigure}
        \caption{Activity-in-the Middle Attack on SSO.}
        \floatfoot{(a) When a
          user wants to login with Facebook in the Instagram,
          Instagram sends system its application ID with application
          secret, Inst\_App\_ID and Inst\_App\_Secret. Android system
          forwards request with Inst\_App\_ID and Inst\_App\_Secret to
          Facebook service provider and retrieves Facebook Login
          Activity bound with Inst\_App\_ID. The user inputs her/his
          username/password for authentication. Facebook service
          provider returns the access token to Android system if the
          authentication passed. Android system sends the access token
        to Instagram according to the application ID that system
        received. (b) The malicious app Mal\_App overrides the
        ownership of the Instagram task in the same way as
        UI-phishing. It monitors the Instagram running status and
        sends system its Facebook login request (including Mal\_App\_ID and
        Mal\_App\_Secret) before the Instagram's request arrives
        Android system. Android system sends Mal\_App's request to
        Facebook service provider and
        drops the same login request arrived later. Facebook return
        Login Activity bound with Mal\_App\_ID. The user inputs her/his
          username/password for authentication. Facebook service
          provider returns the access token to Android system if the
          authentication passed. Android system sends the access token
        to  Mal\_App according to the application ID that system
        received.}
        \vspace{-0.2cm}
           \label{fig:mitm}
\end{figure*}

\subsubsection{Gallery Stealing}
Starting from Android 6.0 (API level 23), in order to access gallery,
an app has to request for \texttt{READ\_EXTERNAL\_STORAGE} permission
at runtime rather than at the installation time, which is classified
as one of the dangerous permissions~\cite{permissionruntime}. This
mechanism provides more secure and flexible protection to user's photo
gallery.  However, this new security mechanism can be bypassed by
exploits to the Android task mechanism, as shown in this subsection.

\noindent\textbf{Timing.} 
For Android devices before \textit{marshmallow} (API level lower than
23), permissions are requested at the time when an app is being
installed. Apps with suspicious permissions will easily trigger the
user's attention and likely be denied access. However, with the new
requesting-permissions-at-run-time mechanism, our attacking app can
avoid requesting permission when being installed since it is requested
at the run time. To figure out the suitable timing, it continuously
monitors Instagram.  Once the victim clicks the ``Camera'' button on
Instagram which allows Instagram to access the gallery and camera, our
attacking app instantly kills Instagram and pops up our requesting
dialog for access photos in gallery. User mistakenly believes that
he/she is granting the permission to Instagram. After the permission
is granted, our attacking app retrieves all the photos from user's
gallery and send them to the back-end server. In order to be
stealthier, the attacking app pops up a dialog shows ``System
encounters errors'' and finally kills itself.

\noindent\textbf{Permission Dialog.}
Even though timing improves the naturalness of the attack, Android
permission dialog shows the name of the app in bold who makes the
request. We propose two ways to circumvent this
problem.
\\\textbf{(1)} By employing the idea of social engineering, the attacker can name the attacking app 
using a name similar to the target app. In our case,
e.g., ``Instgram'' or ``Instagam''. However, naming the app in this way
can hardly pass the review of Google Play. Even if it does, careful
users may still notice the difference. Therefore, in our attack, we do not
use this method.

\noindent \textbf{(2)} Employing the tapjacking. The idea of tapjacking
is putting message the attacker wishes to display on the top of the
real system message by setting a window layout flag
\texttt{TYPE\_SYSTEM\_OVERLAY}. Android realizes the potential threat
and adopts the mechanism
\texttt{MotionEvent.FLAG\_WINDOW\_IS\_OBSCURED} which alerts the real
dialog is being overlaid\cite{flagwindowobscured}. Unfortunately,
Bana\'s\cite{TapjackingIwo} found that \\
\texttt{MotionEvent.FLAG\_WINDOW\_IS\_OBSCURED} is not triggered if
the covered text does not cover the touch points, which are the
buttons in the dialog. Android does not give a patch to the issue.
Instead, it adopts an intent transition scheme to notify the user that
the content is being overlaid starting from Android 6.0 (API level
23). We managed to circumvent the issue by implementing our main
attacking app with \texttt{targetSdkVersion=23}, and in the target app
we tricked the user to install a helper package, which is an
activityless service.  Only app which has the
\texttt{targetSdkVersion=22} and has the overlaying functionality
implemented. It seems tricking users to install additional package is
not applicable, but it is in fact a very common situation for many
apps such as those who require Android SQLite Manager.

The basic steps of the attack model are listed as
follows.

\textbf{(1)} The attack follows the first three steps of UI Phishing
attack.

\textbf{(2)} Once a user presses the camera button of Instagram as
shown in Figure~\ref{fig:gallery}(a), the foreground \texttt{Activity}
will change to
\texttt{"com.instagram.android.creation.activity.\-MediaCaptureActivity"}. Therefore,
Instead of detecting whether the foreground package has changed to
another app, we zoom in the design to focus on changing of the
foreground \texttt{Activity}.

\textbf{(3)} Instead of popping up a counterfeit
page like UI Phishing does, it pops up an \texttt{Activity} which
immediately asks a user for \texttt{READ\_EXTERNAL\_STORAGE} so that
the user thinks he/she is granting the permission to Instagram.

\textbf{(4)} Once the attack app gets the permission, it traverses all the pictures and transmits the image buffers to server.

\textbf{(5)} To achieve better stealthiness, we introduce the
Tapjacking to assist our attack. Its basic idea is to cover the real
texts with some fake texts. Then we are able to change the text of the
permission dialog to ``Allow Instagram to access ...?'' instead of the
real text which is ``Allow GalleryStealing to access ...?'', which is
shown in Figure~\ref{fig:gallery}(b). Once user grants the
permission, the app quickly sends all images as buffer to the server.
Meanwhile, it fools the user by showing a ``system warning dialog''
telling the user that the system encounters an error (shown in
Figure~\ref{fig:gallery}(c)).


\begin{figure*}[t]
        \centering
        \begin{subfigure}[b]{0.325\textwidth}
                \centering
               \includegraphics[width=\linewidth]{4-1}
                \caption{}
        \end{subfigure}
        \begin{subfigure}[b]{0.3\textwidth}
                \centering
          \includegraphics[width=\linewidth]{4-2}
                \caption{}
        \end{subfigure}
        \begin{subfigure}[b]{0.35\textwidth}
                \centering
          \includegraphics[width=\linewidth]{4-3}
                \caption{}
        \end{subfigure}
         \caption{Gallery Stealing Attack.}
         \floatfoot{First the user clicks the camera button highlighted in the first picture. Then the attacking app	kills the real Instagram and pops up its \texttt{Activity} asking for user permission, the text of permission dialog is overlaid by the fake text as shown in the second picture. Once user grants the permission, the app quickly sends all images as buffer to the server, meanwhile, it fools the user by showing a ``system'' warning dialog telling the user the system encounter an error.}
         \label{fig:gallery}
\end{figure*}

\subsubsection{Screen Shot Capturing}
With the ability of knowing which \texttt{Activity} is currently
running in the foreground, we implement this screen shot capturing
attack which starts taking screen shots while a user is entering
username and password in the Facebook \texttt{LoginActivity} which is
\texttt{com.facebook.katana.LoginActivity} in full. For password
typing, every time a character is entered, the character will be shown
for a short time before it turns into a star sign. Therefore, taking
screen shot every 0.1 second should capture everything a user types in
password box.


With respect to taking a screen shot programmatically, we summarize
four possible ways:
\begin{itemize}
\item {\bf Using READ\_FRAME\_BUFFER Permission.}  Declaring
  \texttt{READ\_FRAME\_BUFFER} permission in the \texttt{Manifest}
  allows an application to take screen shots by making calls to
  \texttt{ISurfaceComposer} \cite{framebuffer}. However, this
  permission is not available to third-party application unless it has
  the same signature as the system does.

\item {\bf Using fb*.} Some Linux systems store frame buffers in
  \texttt{/dev/graphics/fb*} or \texttt{/dev/fb*}. \texttt{fb0}
  represents the first frame buffer, \texttt{fb1} represents the
  second frame buffer and so on.  Using native C/C++ code to get
  access to these files and copy the buffer as a \texttt{GGLSurface}
  structure is theoretically possible. But there are two unsolvable
  obstacles of this method:
  \begin{itemize}
  \item This method requires root permission.
  \item It is likely that \texttt{fb*} does not even exist.
  \end{itemize}

\item {\bf Using Backup Channel over USB.}  Android system uses
  Android Debug Bridge (ADB) to listen to the debugging connections
  over USB~\cite{adb}. ADB has slightly more privileges than normal
  apps. Bai {\em et al.}~\cite{DBLP:conf/iceccs/BaiSWYLDG15} manage to
  exploit Backup Channel through ADB to steal access tokens from other
  apps. Combining ADB with Dalvik Debug Monitor Server (DDMS) tool
  enables an app to get the screen shot from the device without any
  permission~\cite{ddms}.

\item {\bf Using MediaProjection.}  For devices beginning in Android
  5.0 (API level 21), a class called \texttt{MediaProjection} was
  added to Android SDK which enables a third-party app to capture
  screen shot and record system audio\cite{mediaprojection}. While
  recording system audio requires \texttt{RECORD\_AUDIO} permission,
  capturing screen shots does not.
\end{itemize}

We employed the fourth method to capture screen shots. The basic steps
of the attack are listed as follows.\\ \textbf{(1)} It follows the
first three steps of UI Phishing. What's different is we devise this
attack to focus on Facebook App since we are hoping to steal user's
Facebook username and password. Hence, we declared this attack to
reside in the same task as Facebook.\\ \textbf{(2)} Once a user launches
the Facebook app, a transparent Activity is popped up start taking
screenshots. Although it does not require permission for taking screen
shots, it uses intent transition to let the user decide whether or not
an app can capture screen shots in a permission-like dialog. Again we
employ the tapjacking in Gallery Stealing attack to cover the text to
be ``Allow Facebook start accessing Internet?'' \\ \textbf{(3)} The
attack starts capturing screens by calling
\texttt{startActivityForResult()} which passes a screenshot as an
intent from which we can extract an object of \texttt{MediaProjection}
later, and finally use this \texttt{MediaProjection} object to pass
the image to an object of \texttt{ImageReader} through its member
function \texttt{createVirtualDisplay}. Since the screenshots are
taken in the \texttt{RGBA\_8888} format while bitmap takes
\texttt{ARGB\_8888}, we still need to do matrix transformations to
get the image.

\begin{figure*}[t]
        \centering
        \begin{subfigure}[b]{0.285\textwidth}
                \centering
               \includegraphics[width=\linewidth]{5-1}
                \caption{}
        \end{subfigure}
        \begin{subfigure}[b]{0.35\textwidth}
                \centering
          \includegraphics[width=\linewidth]{5-2}
                \caption{}
        \end{subfigure}
        \begin{subfigure}[b]{0.31\textwidth}
                \centering
          \includegraphics[width=\linewidth]{5-3}
                \caption{}
        \end{subfigure}
         \caption{Screenshot Capturing Attack.}
         \floatfoot{First the user launches Facebook, then the attacking app launches a transparent \texttt{Activity} which quickly asks for taking screen shot, the notification dialog is again overlaid by fake text as shown in the first picture. Once the user clicks start now, the attacking app begins to take screen shots as well as sending the screen shots to back end server. (b) and (c) are two of the screen shots received by server which expose the password plaintext.}
         \vspace{-0.2cm}
         \label{fig:memory}
\end{figure*}

\subsection{Attack Performance}\label{sec:attackperf}

In order to study the feasibility of the four attacks, we implement them and evaluate them in
two aspects, \emph{time cost} and \emph{memory usage}.
% We check the average running time and the average virtual memory curves to illustrate the performance of our four proof-of-concept attacks.

\subsubsection{Time Cost}
We conduct 6 - 8 rounds of tests for every attack to calculate the average
running time cost. The testing results are summarized
in Table~\ref{tbl:time}. As shown in Table~\ref{tbl:time}, our attacks
are efficient since the time cost of most attacks is less than 8 seconds:
the UI Phishing attack costs 7.1 seconds, which includes user
interactions such as launching Instagram, entering username and
passwords; The Activity-in-the-middle attack costs time 5.8 seconds; and
the average time cost of the gallery-stealing attack is 4.6 seconds.

The Screenshot Capturing attack is an exception, taking 38.1
seconds. This attack uses much longer time because screenshots in
Android are passed in the format of RGBA, while we need to change to
ARGB in order to convert it to common format such as JPEG and PNG.
We perform the matrix transformation required for the conversion on
the mobile device. But since the process is undertaken in the background, it will
not trigger the suspicions of the user. In the real world attack, an
adversary can leave the job of matrices transformation to the server.

\begin{table}[h]
  \centering
\caption{Time Cost of Proof-of-Concept Attacks}
\label{tbl:time}
\begin{footnotesize}
\begin{tabular}{|c|c|}
  \hline
  \textbf{Attack} & \textbf{Time Cost (s)} \\
  \hline\hline
  UI Phishing & 7.1\\
  \hline
  Activity-in-the-Middle & 5.8\\
  \hline
  Gallery Stealing & 4.6 \\
  \hline
  Screenshot Capturing & 38.1\\
  \hline
\end{tabular}
\end{footnotesize}
\end{table}

\subsubsection{Memory Usage}

We conduct 3-round experiments for each attacks to get the memory
distractions of attacks and evaluate their average memory usage. The
testing results are illustrated in Figure~\ref{fig:memory}.  It shows
that the maximum memory usage of most attacks is less than $70MB$ except
Gallery Stealing attack, whose memory usage is around $100MB$. Our
testing results also disclose the memory usage distribution on
different period, in which the major memory usage of each attack is to
launch victim app (normal app), e.g., Instagram and Facebook. The
memory usage differences caused by stealthy behaviors/operations are
negligible.

\begin{figure}[h]
        \centering
        \begin{subfigure}[t]{0.5\textwidth}
                \centering
               \includegraphics[width=\linewidth]{attack1memory.pdf}
                \caption{UI Phishing}
        \end{subfigure}%
        %\quad
        \begin{subfigure}[t]{0.5\textwidth}
                \centering
          \includegraphics[width=\linewidth]{attack2memory.pdf}
                \caption{Activity-in-the-middle}
        \end{subfigure}
        \begin{subfigure}[t]{0.5\textwidth}
                \centering
          \includegraphics[width=\linewidth]{attack4memory.pdf}
                \caption{Gallery Stealing}
        \end{subfigure}%
        %\quad
        \begin{subfigure}[t]{0.5\textwidth}
                \centering
          \includegraphics[width=\linewidth]{attack3memory.pdf}
                \caption{Screenshot Capturing}
        \end{subfigure}
         \caption{Memory Distribution Curves}
         \label{fig:memory}
\end{figure}

In addition, we also conduct experiment to monitor the battery consuming
status and evaluate the battery usage of our attacks. The results show
that our attacks may not cause influence on battery aspect (the
battery usage rates of most attacks are $0\%$).  Above all, the
experiment results demonstrate that our proof-of-concept attacks are
light-weight with limited permission requirements.

\subsection{Solutions to Eliminate Task Interference}\label{sec:atmsolution}
In this subsection, we discuss solutions on mitigating Android task
interference. Based on our study, we design and implement a task
interference checking tool to detect the potential risk of task
interference among apps. It protects apps specified by users from
being manipulated by untrustworthy apps. In addition, we also propose
some suggestions to limit the additional privilege achieved by the
apps in the same task.

\subsubsection{Task Interference Checking}
\label{sec:implementation}
In this subsection, we present the design and implementation of our
\textsl{Task Interference Checking} app named \textsl{TICK}.

Based on our understanding of the task interference problem, which
includes the necessary conditions, events and their dependency, we
design a method to check the task interference status among Android
apps.  Table~\ref{tbl:taskinterference} provides us with the basis of
evaluating task interference checking.

\begin{figure*}[t]
        \centering
                \includegraphics[width=\linewidth]{tick.pdf}
           \caption{Task Interference Checking Architecture}
           \vspace{-0.2cm}
        \label{fig:tick}
\end{figure*}

\textbf{Design.} As shown in Figure~\ref{fig:tick}, \textsl{TICK}
consists of two basic modules, \textsl{Pre-processing} and
\textsl{Interference Checking}, and two supporting databases,
\textsl{Protected App Signature} and \textsl{Task Interference Table}.

\begin{itemize}
\item \textsl{Protected App Signature.} For the apps users who want to
  protect against attacks to Android tasks, this database includes the
  abstracted conditions of such attacks of each app, which is stored as
  signatures in this database.
\item \textsl{Task Interference Table.} This database is the output
  from our research in Section~\ref{sec:atmapproach}, which includes the
  fundamental rules of task interference.
\item \textsl{Pre-processing.} The module takes as inputs the manifest
  files of apps to be checked, abstracts and outputs their task
  interference features for checking.
\item \textsl{Interference Checking.} The interference checking module
  takes inputs from \textsl{Pre-processing} module and \textsl{Protected App
  Signature} database, and checks the suspiciousness of the testing apps
  according to the rules specified in the Task Interference Table.
\end{itemize}

There are two application scenarios for deploying \textsl{TICK}.
\begin{description}

\item[\textbf{C-1:}] Before a user installs an app, she/he can use
  TICK to detect the potential risk of task-related attacks from the app.  TICK
  will parse the app meta data and check with our table and signature
  database to see if it interferes with an existing app. If the app is
  detected to cause interference, TICK will issue a
  warning to the user and suggest she/he not install the app.
\item[\textbf{C-2:}] Our checking app can do chronically scan from
  time to time, check if new packages are added to the device, audit
  if they have security concerns, and notify users if and suspicious
  package were installed.
\end{description}

\textbf{Getting Meta Data of an Activity.}  Currently, our checking app
only considers static declarations of task related attributes from the
app package. Moreover, the key attributes related to Android Task
cannot be altered during runtime, e.g., \textit{taskAffinity} and
\textit{allowTaskReparenting}.

Android SDK provides standard APIs to get an app's Manifest meta data
without requiring any permission. Given a package name and a flag, one
can retrieve an object of \texttt{PackageInfo} through the
\texttt{PackageManager}. Here, we set the flag to
\texttt{GET\_ACTIVITIES} and we retrieve a list of
\texttt{ActivityInfo} by fetching the attribute
\texttt{PackageInfo.activities}. ActivityInfo contains all the meta
data described in the \texttt{Manifest} about every activity of a
package, including those we care, e.g., \texttt{taskAffinity},
\texttt{FLAG\_ALLOW\_TASK\_REPARENTING}, \texttt{LAUNCH\_SINGLE\_TASK}
and so on. The key APIs of getting \texttt{packageManager} and
\texttt{packageInfo} are respectively \texttt{getPackageManager()} and
\texttt{getPackageInfo()}.


\textbf{Effectiveness.} To verify the effectiveness, we used Instagram and our UI-Phishing app
as inputs to TICK. It parsed the meta data of each activity in both
apps and found that most activities of Instagram with {\em
  taskAffinity} set to ``com.instagram.android'', while the rest has
{\em taskAffinity} of
``com.instagram.android.ShareHandlerActivity''. Most of the activities
in Instagram have {\em launchMode} set to ``standard''. A small
portion of the activities have the {\em launchMode} set to
``singleTop'', e.g., the \texttt{LoginActivity}. Very few activities
have {\em launchMode} set to ``singleInstance''. The UI-Phishing app's
first activity has the following flags set: \texttt{taskAffinity =
  "com.instagram.android"}, \texttt{allowTaskReparenting = true} and
\texttt{launchMode = standard}. This matches Case 9 and Case 10 in our
task interference table. When we use TICK to scan the device,
specifying the Instagram app as the one to be protected, TICK
successfully warns users about the potential risk from the UI-Phishing
app. The overhead of TICK can vary based on a number of factors such as device hardware and number of third-party Apps installed in the device. In our experiment, excluding all system-level Apps, there are totally 65 third-party Apps installed in our device. It rougly took 4-5 seconds to scan all Apps and identify suspicious ones.

\subsubsection{Design Suggestions}

From security issues we have demonstrated in the above attacks, it is
clear that the privilege given to apps in the same task is well beyond
what is expected for a mechanism that facilitates app collaboration
and interaction. In fact, the task mechanism should be treated as a
way of {\em authorization}, and the security mechanism around the task
mechanism also should be designed accordingly.

In particular, when treating a task as a boundary for authorization,
we need to be explicit about the ownership of a task and its
authenticity. For example, if an app specifies the {\em taskAffinity}
of an existing task, there needs to be a form of {\em authorization}
before the app can be included into the task, and the authorization
should be carried out by entities with privilege greater than the
privilege given to the task. This is similar to the requirement made
by the UNIX group mechanism. In addition, as the name of ``task affinity''
becomes an identifier for a security object, the system should avoid
name conflicts. In case they occur, they need to be resolved with all
involving entities to avoid unexpected privilege escalation.

\subsection{Related Works}\label{sec:atmrelated}
\textbf{IPC Security:} IPC security is one of the top concerns while
designing OSes. Some early studies have reported security threats in
the Android IPC mechanism. More specifically, Ren
et al.~\cite{TaskHijacking} have proposed the first study of the
security of Android task mechanisms and showed the possibilities of
several enabled attacks, such as back-button hijacking and
uninstalling-prevention attack. Other popular mobile systems like iOS
are also not immune to the risks. Xing et al.~\cite{CrackingiOS}
registered a counterfeit scheme which hijacks the real Facebook scheme
in iOS and successfully stole a Facebook access token that was
supposed to be passed onto the relying-party app. Besides problematic
designs of IPC of OSes, mis-implementation of certain IPC-based
protocols can also lead to security concerns. Chen
et al.~\cite{OAuthDemystified} have conducted an analysis on 149
mobile applications and showed 89 of them (59.7\%) incorrectly
implemented OAuth and thus are vulnerable to SSO-oriented attacks.
Furthermore, IPC vulnerabilities were also documented on other
platforms besides mobile OSes. Take browser platform for an example.
Wang et al.~\cite{webssoattack} discovered 8 serious logic flaws among
the traffics between high-profile ID provider and relying website
through browser platform. Wang et al.~\cite{shopforfree} discovered
logic flaws in several shopping websites and finally purchasing goods
without or with little payment.

\textbf{GUI Security:} As for traditional desktop and browser
environment, GUI security issues have been studied
extensively~\cite{nitpickers,secuserinterface}. Niemietz
et al~\cite{uiredress} implement a UI redressing attacks on Android
devices base on clickingjacking and tapjacking and the attack is
feasible to be transferred from desktop to mobile and to browser,
enabling the attack to be adapted to multiple platforms and
functionalities. As mobile market begins to thrive, GUI security is
more concerned in mobile platforms than ever before. Chen
et al.~\cite{UIstateinference} managed to impose Hidden Markov Model
(HMM) on a public resource \texttt{shared\_vm} combining a bundle of
data to perform UI Inference Attack and successfully stole sensitive
information from users such as user names, passwords and check images.
Wang et al.~\cite{jekyll} implemented a malicious app which
circumvented the Apple Code Review system and successfully stole user
secrets stealthily. 

\textbf{Defending against Malicious Behaviors:} Defending malicious
behaviors can be categorized into two branches, detection and
prevention. In previous studies, various detection schemes have been
introduced to prevent GUI-related attacks. Fu
et al.~\cite{detectpswebsite} employ the Earth mover's distance (EMD)
mechanism to detect possible malicious web page through measuring the
similarity between two web pages by first converting web pages to
images, and then grabbing and comparing the feature points through
training data set. More generally, Chen et al~\cite{peg} introduce the
concept of permission event graph (PEG) with model checking mechanisms
to detect abnormal behaviours of Android apps. As for prevention, one
idea is to prevent sensitive data from being leaked to the malicious
server party. Hornyack et al.~\cite{AppFence} develop a
system for Android called AppFence, which can block the sensitive data
from being transmitted, or substitute the fine-grained data to
coarse-grained data if transmission is unpreventable. Ren
et al.~\cite{Windowguard} develop WindowGuard which protect against GUI
attacks by enforcing the Android Window Integrity (AWI).

   \newpage
   \begin{singlespace}
   \section{I Know Your Social Network Accounts: A Novel Attack Architecture for Device-Identity Association}
   \end{singlespace}
   \label{sec:dssnassociate}
   
   \subsection{Threat Model and Approach Overview}\label{sec:dssnthreatapproach}
   In this subsection, we present the threat model and the overview of our attack approach.

\subsubsection{Threat Model}\label{sec:dssnthreat}
We consider an attacker who can accomplish inference attacks through a malicious app installed on a victim's device with no special permission -- this malicious app only requests the \texttt{INTERNET} permission from Android to send the collected data to the attacker for analysis, which by default is automatically granted by the Android system without notifying the user. How to install a malicious app in a victim's device is out of the scope of this paper. Here are a few viable approaches: an attacker can trick a user to install a malicious app by simply disguising the app as a benign one and putting it on the Google Play Store since current automatic malware detection for Android is still not sufficiently reliable \cite{googleplaymalware}; alternatively, an attacker can secretly install a malicious app on a victim's device by exploiting a remote code execution (RCE) vulnerability such as CVE-2017-0561, which allows RCE on Wi-Fi SoC \cite{wifirce}. In this paper, we assume that a malicious app has already been installed on the victim's device. This malicious app can silently collect and send to the attacker certain system states that are publicly available.

\subsubsection{Approach Overview}\label{sec:dssnapproachoverview}
The objective of our design is to associate an Android device (running social network apps to perform social activities such as posting a photo or a message) with the social network accounts (the accounts accessed by the device) based on the following publicly available information: (i) the system state information (see Section~\ref{sec:preliminaries}) collected by a malicious app installed in the victim Android device; and (ii) the social network events crawled from the social network databases. We consider three popular social networks: Twitter, Flickr, and Instagram, and exploit the tweeting events in Twitter and photo-posting events in Flickr and Instagram for our studies on device-identity association. 

\begin{figure}[!htb]
  \centering
    \includegraphics[width=\textwidth]{overview.png}
    \caption{Attack architecture}
    \label{fig:overall}
\end{figure}

Our attack architecture is shown in Figure~\ref{fig:overall}. It is composed of two attack vectors: \emph{device-social network correlation (DS-SN)} attack and \emph{social network-social network correlation (SN-SN)} attack. The objective of the DS-SN attack is to identify a list of candidate accounts that might have been accessed via the device for a target social network. We developed an approach to infer a user's social network events from his device system states. More specifically, we leveraged the system states collected by a zero-permission malicious app installed in the user's device to identify the events triggered by the social network app, e.g., the time to tweet and the size of the tweet in Twitter, or the time of posting a photo in Flickr/Instagram. By correlating such information with the public events in the target social network, one can identify a list of candidate accounts in the social network for the user who may have used the device to access his account. To uniquely identify the social network account accessed via the device, one can observe multiple social network events triggered by the device to shorten the candidate account list, which may take a long time if the user does not frequently access his account via the device. If the device is used to access multiple accounts of the same user belonging to different social networks, the attacker can employ the SN-SN attack that examines the profile similarity between two social network accounts from two different social networks to identify the most possible account for the user in each social network. More specifically, the attacker first obtains the candidate account lists for two (or more) social networks via the DS-SN attack, then calculate the profile similarity of two accounts, with one from each account list, and identify the pair of accounts with the highest similarity. Such a SN-SN attack can not only speedup the process of device-identity association attack, but also help identify two or more social network accounts accessed via the same device for the victim.

\subsection{Design and Implementation of Our Attacks}\label{sec:dssnapproach}
In this subsection, we detail our design of the two inference attacks: DS-SN attack and SN-SN attack.

\begin{table}[!htb]
\centering
\caption{Summary of the DS-SN Attack}
\label{tbl:ds-sn-summary}
\resizebox{\columnwidth}{!}{
\begin{tabular}{|c|c|c|c|}
\hline
\hline
                         & Inferred SN Events                                                            & \begin{tabular}[c]{@{}c@{}}Corresponding \\ Activity Transition\end{tabular} & \begin{tabular}[c]{@{}c@{}}Corresponding\\ System States\end{tabular}                                                                                          \\ \hline \hline
\multirow{2}{*}{Twitter} & Tweeting Timestamp                                                         & \begin{tabular}[c]{@{}c@{}} \texttt{MainActivity}\\ $\Downarrow$\\ \texttt{ComposerActivity}\end{tabular} & \begin{tabular}[c]{@{}c@{}}\emph{VSS} of Twitter\\ \texttt{tcp\_snd} of Twitter\\ \texttt{tcp\_rcv} of Twitter\end{tabular}                              \\ \cline{2-4} 
                         & \begin{tabular}[c]{@{}c@{}}Number of Characters \\ of a Tweet\end{tabular} & N/A                                                                           & \begin{tabular}[c]{@{}c@{}}\texttt{utime} of Keyboard\\ \texttt{stime} of Keyboard\end{tabular}                                                            \\ \hline
Instagram                & Photo-posting Timestamp                                                    &\begin{tabular}[c]{@{}c@{}} \texttt{MediaCaptureActivity I}\\ $\Downarrow$\\ \texttt{MediaCaptureActivity II} \end{tabular}      & \begin{tabular}[c]{@{}c@{}}\emph{VSS} of Instagram\\ \texttt{tcp\_snd} of Instagram\\ \texttt{tcp\_rcv} of Instagram\end{tabular}                        \\ \hline
Flickr                   & Photo-posting Timestamp                                                    & \begin{tabular}[c]{@{}c@{}} \texttt{MainActivity}\\ $\Downarrow$\\ \texttt{FilterUploadActivity}   \end{tabular}    & \begin{tabular}[c]{@{}c@{}}\emph{VSS} of Flickr\\ \emph{RSS} of Media Process\\ \texttt{tcp\_snd} of Flickr\\ \texttt{tcp\_rcv} of Flickr\end{tabular} \\ \hline
\end{tabular}
}
\end{table}

\subsubsection{DS-SN Correlation Attack}\label{sec:dssnattack}
Our approach to attacking the DS-SN correlation is composed of 4 steps: 1) obtaining system states from a victim's device via a zero-permission malicious app, 2) inferring activity transitions in the device, 3) inferring the corresponding social network events triggered by the device, and 4) associating the victim's device with his social network account based on the inferred events triggered by the device and the publicly available events crawled from the target social network. We considered three popular social networks: Twitter, Flickr, and Instagram. Our purpose is to infer the tweeting time of and the number of characters in a tweet for Twitter, the posting time of a photo in Instagram, and the posting time of a photo in Flickr. This inference is based solely on the publicly available information: the Android system states collected by a zero-permission app and the tweeting/photo-posting events crawled from the social network databases. The device state information needed by the DS-SN attack as well as the inferred device activity transitions and social network events for the three social networks are presented in Table~\ref{tbl:ds-sn-summary}.

\textbf{Obtaining System States.}

As shown in Table~\ref{tbl:ds-sn-summary}, we exploited \emph{VSS}, \emph{RSS}, \texttt{utime}, \texttt{stime}, \texttt{tcp\_snd}, and \texttt{tcp\_rcv} for our DS-SN attack. There are multiple ways to obtain these system data in Android, as elaborated in Section~\ref{sec:preliminaries}. The most intuitive way is to make calls to the Android APIs. However, one has to retrieve the three types of data using different APIs, making this method less efficient. To overcome this problem, we first leveraged the ``\texttt{ps}'' command with Android Toolbox \cite{toolbox}, which can return the memory and CPU data in one call; then we directly read the system files \texttt{/proc/uid\_stat/pid/tcp\_snd} and  \texttt{/proc/uid\_stat/pid/tcp\_rcv} to retrieve the network data. 

\begin{figure}[!htb]
  \includegraphics[width=\textwidth]{swipe.pdf}
  \caption{The variations of \emph{VSS} of the Twitter app in four different Android devices within approximately 2 minutes of swiping and tweeting.}
  \label{fig:swipe}
\end{figure}


\textbf{Inference of Activity Transitions}

Activity transition is one of the most critical states to infer private information from an app. Previous research done by Chen \emph{et al.} \cite{chen2014peeking} described an approach that can infer an app's activity transition using a Hidden Markov model (HMM) over the memory data and then further infer the current foreground UI/activity the user is landing on. We tested this approach in our Android devices but failed to make it work. A careful study indicates that this approach is quite sensitive to the quality of the memory data but social network apps when running constantly incur significant noises compared with the clean acctivity transitions considered in \cite{chen2014peeking}. Figure~\ref{fig:swipe} illustrates the variations of the \emph{VSS} of the Twitter app in four Android devices with different OSes when we performed swiping and tweeting for approximately two minutes. Note that people usually swipe when tweet; thus these two activities are commonly performed together. From this study one can conclude that social network apps incur noisy memory data in most Android OSes, and the HMM inference method would face challenges when distinguishing tweeting from swiping. Having noticed this fact, we propose our own approach to precisely infer the activity transitions with the noisy memory data.

To proceed, we take a look at the VSS changes of the three social networks (see Figure~\ref{fig:memory-activity}) when only a posting event is performed - no other activities such as swiping and tapping is involved to remove noise. One can see from Figure \ref{fig:memory-activity} that the activity transition of tweeting (from \texttt{MainActivity} to \texttt{ComposerActivity}) takes 4 time intervals\footnote{Here we refer a time interval as the time span needed for the retrieval of one record of the system states, which can differ from device to device but normally it is within 0.5$\sim$0.6 seconds}; the one for photo-posting in Instagram (from (\texttt{MediaCaptureActivity I} to \texttt{MediaCaptureActivity II}) takes 12 time intervals; while the one for photo-posting in Flickr (from \texttt{MainActivity} to \texttt{FilterUploadActivity}) takes only one time interval. Thus obviously, it is hard to design a uniform approach that can work for all the three social networks. In this subsection, we propose a novel \emph{memory pattern regression} model that can infer the activity transitions based on the VSS variations for Twitter and Instagram, and employ the RSS of the system media process\footnote{We employed RSS for Instagram too but our memory pattern regression model performs better.} to infer the activity changes in Flickr. In the following, we first detail our novel memory pattern regression model. 


\begin{figure}[!htb]
  \includegraphics[width=\textwidth]{activity-memory.pdf}
  \caption{The variations of \emph{VSS} of Twitter, Instagram, and Flickr when a tweet or a photo is posted. The red parts refer to the activity transitions of tweeting/photo-posting in the corresponding social network.}
  \label{fig:memory-activity}
\end{figure}


{\noindent \bf Memory pattern regression.}
Our memory pattern regression algorithm takes as input the training set $D=\{\mathbf{y}_j\}_{j=1\cdots d}$, which is the memory data tested $d$ times for a single activity transition with $\mathbf{y}_j = (y_{j_1}, y_{j_2}, \cdots, y_{j_{N_j}})$ being the \emph{VSS} vector of size $N_j$ obtained in the $j$-th experiment. We first need to find out the number $n$, which represents the number of time intervals in which a target activity transition, i.e., an activity transition of a tweeting in Twitter or a photo-posting in Instagram, takes place. In order to determine $n$, we first construct a sequence $\mathbf{\Delta y_j} = (\Delta y_{j_1},\cdots,\Delta y_{j_{N_j-1}})$, where $\Delta y_{j_i}=|y_{j_{i+1}}-y_{j_i}|$; %, and $\mathbf{\Delta y_j}$ has $N-1$ terms since each term of $\mathbf{\Delta y_j}$ is a pair of consecutive terms from $\Delta y_{j_i}$; 
then we set up a threshold $\delta$, which can be determined experimentally, and let $n_j$ be the number of terms in $\mathbf{\Delta y_j}$ whose values are greater than $\delta$; finally %we let $n_j$ be the number of differences between the greatest index and the smallest index of the extracted terms, and
we set $n=\ceil{\frac{\sum_{j=1}^{d} n_j}{d}}$.


Having determined $n$, we proceed to extract the \emph{VSS} change pattern of a transition. Instead of directly using the raw data of \emph{VSS}, we use slopes of each pair of adjacent \emph{VSS} points since doing this can not only mitigate the noises of memory but also obtain the shape of the transition (i.e., pattern). In order to do so, we minimize a function
$f:\mathbb{R}^{n+1}\longrightarrow \mathbb{R}^{n+1}$, which is represented as
%
\begin{equation} \label{eq:msef}
f \leftarrow \argminA_f\{\frac{1}{d}\Sigma^d_{j=1}
[\frac{1}{n}\Sigma^{n}_{i=1}(\Delta f(j_i)-\Delta y^\prime_{j_i})^2]\}
\end{equation}
where $\Delta f(j_i)=f(j_{i+1})-f(j_i)$ 
is the slope between the point $j_{i+1}$ and $j_i$ since $j_{i+1} - j_i=1$, and 
$\Delta y^\prime_{j_i}$ is the $i$th term in the consecutive interval of $\mathbf{\Delta y_j}$ with size $n$ that covers the maximum number of values greater than $\delta$.


In order to learn the $f$ satisfying \eqref{eq:msef}, we employ a 5-layer feedforward neural network with $n$ neurons at each layer. In this deep neural network, each neuron in the input and output layers is connected to a neuron (one-to-one) in the adjacent hidden layers, but all the hidden layers are fully connected. Moreover, the input and output layers simply use the Hadamard product as the activation function while all other layers use the Sinusoid function for activation. 

The neural network adopted in our approach was implemented based on the Google TensorFlow \cite{abadi2016tensorflow} deep learning framework with the Adam stochastic optimization \cite{kingma2014adam} that takes the right part of (\ref{eq:msef}) as a loss function. By minimizing the loss function, we can obtain $\mathbf{v_j}=( \Delta f(j_1),\Delta f(j_2),...,\Delta f(j_{n}))$ as the \emph{VSS} pattern, which is related to an activity transition with $n$ pieces of slopes. 

Let $\mathbf{y}=(y_1,...,y_N)$, with $N>n$, be the \emph{VSS} sequence collected from a victim's device. The question here is: how can we tell whether the target activity transition happens in this sequence based on the pattern $\mathbf{v_j}$? Intuitively, directly determining whether the Euclidean distance  between them is smaller than a threshold $\sigma$, i.e., $\|\mathbf{v_j}-\Delta\mathbf{y}\|<\sigma$ with $\Delta\mathbf{y}$ being $n$  consecutive slops of $\mathbf{y}$, seems reasonable. However, the Euclidean distance is not applicable in our case since if a user constantly uses an app without quitting, the \emph{VSS} of the App would accumulate. Thus clearly, statically setting a threshold can result in a gradually larger error. Therefore, we developed a comparison method which fits our problem well. Instead of directly considering $\Delta\mathbf{y}$, we tolerate a little bit by considering a neighborhood of $\Delta\mathbf{y}$, denoted by $B_{r}(\Delta\mathbf{y})$, where $r$ is a small integer such that $n<r< N$. Specifically, for a \emph{VSS} value at $i$, we consider the previous and post $r$ slopes of this value, yielding $B_{r}(\Delta y_{i})=(\Delta y_{i-r},...,y_{i},...,\Delta y_{i+r})$ (totally $2r+1$ terms). After that, given a threshold $\sigma$, our comparison algorithm extracts each continuous segment of slopes with size $n$ from $B_{r}(\Delta\mathbf{y_j})$ and calculates the mean squared errors with $\mathbf{v_j}$, denoted as $mse_1,mse_2,...,mse_{2r+2-n}$ (totally $2r+2-n$ terms). Lastly, if $\max(|mse_1-mse_2|,|mse_2-mse_3|,...,|mse_{2r+2-n}-mse_{2r+2-n}|)<\sigma$, we perceive that the target activity transition occurs in $B_{r}(\Delta y_{i})$.

For the activity transition inference of the photo-posting event in Flickr, we employed a different approach based on the following observation: when posting a photo in Flickr, a user needs to choose a picture from his album or to take a photo; in this case, the \emph{RSS} of the system media process, i.e., \texttt{android.process.media}, increases and the \emph{VSS} of Flickr increases. Therefore, using this information, one can infer that an activity transition of a photo-posting event occurs in Flickr. Note that even though Instagram is also a photo-based social network, this method does not apply to it because Instagram allows a user to post comments with a picture. Therefore, if directly using this method in Instagram, one may not be able to tell if a user posts a photo or just sends a comment.

\textbf{Inference of Social Network Events}

To infer the timestamp of a tweeting/photo-posting event, we need to check not only the corresponding activity transitions implied by the memory state changes but also the network states of the device: the existence of an activity transition alone does not mean that the event actually has happened - it is completed only after the tweet message or the photo is sent via the network. Therefore, we need to figure out whether \texttt{tcp\_snd} and \texttt{tcp\_rcv} increase after the detection of the activity transition\footnote{One can use only \texttt{tcp\_snd} for the event inference but our experiments indicate that both \texttt{tcp\_snd} and \texttt{tcp\_rcv} increase when an event occurs, which is reasonable as TCP connections involve two-way traffics.}. In other words, an attacker can infer when a tweeting/photo-posting event happens by combining activity transitions with the network \texttt{tcp\_snd} and \texttt{tcp\_rcv} information. 

%\subsubsection{Inference of the Number of Characters in a Tweet Message}
In Twitter, we can also infer the number of characters in a tweet message by the keyboard event. Note that after a tweet is posted, keyboard would disappear and \texttt{tcp\_snd} would increase. However, we cannot use \texttt{tcp\_snd} to precisely estimate the number of characters sent in a tweet due to the protocol overhead of TCP connections. In our approach, we resort to CPU usage information. We found that the system states of the Android keyboard process (\texttt{com.google.android.inputmethod.latin}) are tightly related to a user's typing actions. More specifically, when the keyboard is launched, the \emph{VSS} of the keyboard process increases drastically from a constant state; when a user types a keystroke, the \texttt{utime} and the \texttt{stime} of the keyboard process roughly increase by 1 clock tick. Thus we took the ceiling of the averaged increased clock ticks of \texttt{utime} and \texttt{stime} to estimate the number of characters in a tweet message. %Figure \ref{fig:utime-vtime} illustrates the changes of \texttt{utime} and \texttt{vtime} for a keyboard process. 

\textbf{Associating Device with Social Network Accounts}

After retrieving the targeted social network events based on the Android system states, i.e., the timestamps of the posts and the sizes of the tweets, we can repeatedly match this information with the public information of the target social network to obtain a gradually smaller list of potential social network accounts for the device. For example, from the device system states we inferred that our target victim tweeted twice in two different timestamps and estimated the sizes of these two tweets. Then we proceeded to crawl the Twitter database and filter out those who did not tweet in these two timestamps and whose tweet sizes do not match with our inferred tweet sizes. By this way we can get a reasonably small list of potential Twitter accounts that may be associated with the victim with a high probability. %Similarly, we can carry out the inference attack for Flickr and Instagram.


\textbf{Crawling the Social Network Events}

As mentioned earlier, we need the public information of the target social network to realize the DS-SN attack. More specifically, we need to crawl the tweets/posts occurring at a specific time within a social network. However, it is not trivial to retrieve the required data from the three social networks under our consideration. We have to overcome the following challenges.

First, even though Twitter has a streaming API which provides an interface to facilitate the retrieval of the tweets for a given time period, this method does not work since the API tends to drop a large amount of unimportant data and it has a rate limit. Luckily, we found that Twitter offers a webpage called Twitter Advanced Search (TAS) via which we can retrieve a list of tweets that contain the queried keywords, locations, or user accounts, for a given time period.
Since user accounts are what we want to
retrieve, we cannot use accounts as a filter. Therefore, 
we query with letters from ``a'' to ``z'' as the filtering keywords, 
and the TAS server replies a list of tweets containing any letter from ``a'' to ``z''
with very minimal data loss - the Twitter server fails to return some tweets only when it thinks that these tweets are duplicates or these tweets only contain non-English contents. Hence, we leverage this method by making
queries through TAS with 26 letters and set the time period to be 1 minute.
We wrote a program that sends a url in the following format:
\begin{lstlisting}[basicstyle=\scriptsize]
https://twitter.com/i/search/timeline?f=tweets&vertical=default&q= keyword%20since%3Astart_date%20until%3Aend_date&src=typd&include_available_features=1&include_entities=1&lang=en&max_position=TWEET-old_tweet_id-new_tweet_id-BD1UO2FFu9QAAAAAAAAETAAAAAcAAAASAAAA...A&reset_error_state=false
\end{lstlisting}
where \emph{new\_tweet\_id} is the tweet id of the very first tweet
shown in the result, while \emph{old\_tweet\_id} is the id of the 
last tweet received. Then TAS returns a JSON file containing 20 tweets
for each query sorted by the posting times. Note that this method requires us to recurrently query until we retrieve all the tweets for our desired time period. We
found that in average there are approximately 30,000 - 60,000 new
tweets generated globally at every minute. 

Flickr offers a similar search engine that does not require the inputs of keywords, locations, and so on. In other words, by merely feeding
a time period to the Flickr search engine one can retrieve all the posts
of that time period. Based on our observation, Flickr follows the following format to retrieve posts:
\begin{lstlisting}
https://api.flickr.com/services/rest?sort=relevance&parse_tags=1&content_type=7&extras=can_comment%2Ccount_comments%2Ccount_faves%2'Cdescription%2Cisfavorite%2Clicense%2Cmedia%2Cneeds_interstitial%2Cowner_name%2Cpath_alias%2Crealname%2Crotation%2Curl_c%2Curl_l%2Curl_m%2Curl_n%2Curl_q%2Curl_s%2Curl_sq%2Curl_t%2Curl_z&per_page=100&page=xx&lang=en-US&advanced=1&min_upload_date=start_time&max_upload_date=end_time&viewerNSID=xx&method=flickr.photos.search&'csrf=xx&api_key=xx6&format=json&hermes=1&'hermesClient=1&reqId=xx&nojsoncallback=1'
\end{lstlisting}
where \emph{start\_time} and \emph{end\_time} are Unix times. The
server returns a JSON file containing 100 posts for each requested
page number. Here a page number represents the index of the Flickr post pages, with each page containing 100 posts. For example, the third page (page number three) contains the 301st to the 400th posts following a descending posting time. We wrote a program that keeps on sending the url until all pages have been returned.

In contrast, Instagram does not have any interface for
returning posts based on time; instead, it provides an interface that
returns posts based on locations, accounts, and hashtags. Therefore, we
can only collect as many user accounts as possible for further scrutiny.
Due to the nature of Instagram, almost every
Instagram user follows at least one verified account (celebrity). Thus we
collected all the followers of the official account of Instagram, Selena Gomez, and Taylor Swift, the top three most-followed accounts on
Instagram. As a result, we obtained in total 390,592,786 users while the
number of active Instagram users is about 500 million to 600
million \cite{instdata}. To collect the followers of the three most-followed accounts, we wrote a program that sends a post data to the url \texttt{
\url{https://www.instagram.com/query/}} with the format of
\begin{lstlisting}[language=json,firstnumber=1, basicstyle=\scriptsize]
"q": "ig_user(xxx)
{ followed_by.after(end_cursor, step)
{count,page_info
{ end_cursor, has_next_page}, nodes {id, is_verified,
followed_by_viewer, requested_by_viewer, full_name, profile_pic_url, username}
}
}"
\end{lstlisting}
where \emph{end\_cursor} indicates the cursor of the last retrieved user and \emph{step} indicates the number of users returned at each round.


\subsubsection{SN-SN Correlation Attack}
\label{sec:snsnattack}
Our SN-SN correlation attack is designed to assist the DS-SN attack since the latter may not always be feasible (e.g., taking too long time) due to the infrequency of successive tweets/posts in a single social network by the target victim. To understand this challenge, we carried out a measurement study over 500,008 users randomly selected from the followers of 10 celebrities in Twitter to collect the time intervals between the most recent two successive tweets. As one can see from Figure~\ref{fig:timediff}, over half of these Twitter users tweeted again more than 20 days later after their last tweet. Therefore, if only exploiting the DS-SN correlation, an attacker may have to wait for a long time to collect enough data for a satisfying result. Nevertheless, a user may access different social networks with the same device at different times; thus exploiting the correlations of the accounts in different social networks may help speedup and enhance the accuracy of the device-identity association attack. In this subsection, we investigate the SN-SN correlation to identify the possible accounts in different social networks for the same user, which can help shorten the list of candidate accounts obtained from the DS-SN attack. Assume that an attacker has launched the DS-SN attack on a victim device for two social networks and obtained two lists of candidate accounts. Then the objective of our SN-SN attack is to identify the accounts that can match to the same user with high probability. This is done by the so-called \emph{profile similarity}, which is a weighted average of the similarities of five attributes:  \textit{location} ($s_1$), \textit{personal website link} ($s_2$), \textit{username} ($s_3$), \textit{biography} ($s_4$), and \textit{profile image} ($s_5$). A novel learning-based model is presented to calculate the weight for each attribute.  %Then we define an overall similarity which aggregates all these similarity metrics into a weighted representation. Lastly, we employ a learning-based method to find the weights for overall similarity to refine our results.

\begin{figure}[!htb]
  \includegraphics[width=\textwidth]{distribution3.pdf}
  \caption{The number of users \emph{vs.} the time difference between two
    successive tweets. One can see that the majority of the Twitter
    users tweeted twice between 20 days to 30 days. %; thus it is not always
    %easy to retrieve multiple tweets from a single user.
    }
  \label{fig:timediff}
\end{figure}

In the following we present the definitions of the five attribute similarities. For better elaboration, we use $u_1^{t_1}$ and $u_2^{t_2}$ to refer to the two accounts in social network $t_1$ and $t_2$, respectively. 

\noindent \theoremstyle{definition}
\begin{definition}[Location Similarity, $s_1$]
Let $p_{1}^{t_1}$ and $p_{2}^{t_2}$ be the locations set by $u_{1}^{t_1}$ and $u_{2}^{t_2}$, respectively. The location similarity score $s_1$ is defined as
\begin{equation}
s_1(p_{1}^{t_1},p_{2}^{t_2})=
\begin{cases}
1 & if\ p_{1}^{t_1} \mbox{ and } p_{2}^{t_2} \mbox{ are the same},\\
0 & otherwise.
\end{cases}
\end{equation}
\label{def:loc}
\end{definition}
In the social networks we consider, the location in a user's profile follows the format of ``\textit{City, State/Province, Country}'' (a user is not mandatory to fill out all these three fields); a user can also upload the longitude and latitude of his location. In this study, we consider two locations to be the same if (1) cities are the same; or (2) states/provinces are the same; or (3) the Euclidean distance between two coordinates does not exceed 814 miles, which is the approximate diameter of the largest state, Alaska, in the US \cite{alaska}.

\noindent \theoremstyle{definition}
\begin{definition}[Personal Website Link Similarity, $s_2$]
Let $p_{1}^{t_1}$ and $p_{2}^{t_2}$ be the personal website links set by $u_{1}^{t_1}$ and $u_{2}^{t_2}$, respectively. The personal website link similarity score $s_2$ is defined as
\begin{equation}
s_2(p_{1}^{t_1},p_{2}^{t_2})=
\begin{cases}
1 & if\ p_{1}^{t_1}=p_{2}^{t_2},\\
0 & otherwise.
\end{cases}
\end{equation}
\label{def:pw}
\end{definition}
%Here we consider if two personal websites are the same if the links are the same.

\noindent \theoremstyle{definition}
\begin{definition}[Username Similarity, $s_3$]
Let $p_{1}^{t_1}$ and $p_{2}^{t_2}$ be the usernames of $u_{1}^{t_1}$ and $u_{2}^{t_2}$, respectively. The username similarity score $s_3$ is defined as
\begin{equation}
s_3(p_{1}^{t_1}, p_{2}^{t_2})=\frac{|lcs(p_{1}^{t_1},p_{2}^{t_2})|}{\max(|p_{1}^{t_1}|,|p_{2}^{t_2}|)}
\end{equation}
where $lcs(str_1,str_2)$ denotes the \emph{longest common substring} of strings $str_1$ and $str_2$.
\label{def:user}
\end{definition}

\noindent According to the latent semantic analysis (LSA) in NLP \cite{landauer1998introduction}, we defined the biography similarity in the following manner.
\noindent
\begin{definition}[Biography Similarity, $s_4$]
Let $p_{1}^{t_1}$ and $p_{2}^{t_2}$ be the biographies of $u_{1}^{t_1}$ and $u_{2}^{t_2}$, respectively, where $p_{1}^{t_1}$ contains $m_1$ unique words and $p_{2}^{t_2}$ contains $m_2$ unique words. The frequency vector $\vv{fq}(p_{1}^{t_1,4},p_{2}^{t_2})$ is defined as the number of times each word of $p_{1}^{t_1}$ appears in $p_{2}^{t_2}$, i.e., 

$$\vv{fq}(p_{1}^{t_1},p_{2}^{t_2})=\left( 
z_{1},
z_{2},
\cdots,
z_{m_1}
\right)^T$$
with $z_i$ being the number of times the $i$th word of $p_{1}^{t_1}$ appearing in $p_{2}^{t_2}$.
%
Let $F=\vv{fq}(p_{1}^{t_1},p_{2}^{t_2})\cdot \vv{fq}(p_{1}^{t_1},p_{2}^{t_2})^{T}$.  We perform the SVD decomposition against $F$ and retrieve $F$'s singular value vector, which is denoted by $\delta=(\delta_1,\dots,\delta_{m_1})$. Then
the biography similarity $s_4(p_{1}^{t_1},p_{2}^{t_2})$ is defined as
 %
\begin{equation}
\begin{gathered}
s_4(p_{1}^{t_1},p_{2}^{t_2})= \min(\frac{\left\Vert \varSigma\right\Vert _{F}}{\left|p_{1}^{t_1}\right|\left|p_{2}^{t_2}\right|},1)=\min(\frac{\sqrt{\sum_{i=1}^{m}\delta_{m_1}^{2}}}{\sqrt{m_1\cdot m_2}},1)
\end{gathered}
\end{equation}
\label{def:bio}
\end{definition}

\noindent Lastly, due to the special nature of profile images, we consider a profile image with and without human faces separately. %separate the profile images into two types based on whether or not there are human faces in the images.
\noindent
\begin{definition}[Profile Image Similarity, $s_5$]
Let $p_{1}^{t_1}$ and $p_{2}^{t_2}$ be the profile images of $u_{1}^{t_1}$ and $u_{2}^{t_2}$, respectively. The profile image similarity score $s_5$ is defined as:
\begin{equation}
s_5(p_{1}^{t_1}, p_{2}^{t_2})=\begin{cases}
s^F_5(p_{1}^{t_1}, p_{2}^{t_2}), \hbox{both have faces};\\
s^{\neg F}_5(p_{1}^{t_1}, p_{2}^{t_2}), \hbox{none has face};\\
0, \hbox{otherwise}.
\end{cases}
\end{equation}
\label{def:image}
\end{definition}

\noindent For the case when both profile images contain human faces, our approach compares the facial similarity in three steps: (1) \textit{face detection}, (2) \textit{face aligment}, and (3) \textit{face similarity comparison}. In the face dection step, we leverage the Haar Feature-based Cascade Classifier proposed by \cite{viola2001rapid}\cite{lienhart2002extended}; in the face aligment step, we leverage the Multitask Cascaded Convolutional Network proposed and implemented by Zhang \emph{et al.} \cite{zhang2016joint}; and finally, we come up with the face similarity definition motivated by the FaceNet proposed by Schroff \emph{et al.} \cite{schroff2015facenet}. Embedding \cite{schroff2015facenet} is a function $f_{emb}$ whose $L^2$ norm satisfies $\left\Vert f_{emb}(x)\right\Vert _{2}=1$. In our study, we define $f_{emb}$ as
\begin{equation}
f_{emb}(px_{i,j})=\frac{px_{i,j}}{\sqrt{\sum_{i} \sum_{j} px_{i,j}^{2}}}
\end{equation}
where $px_{i,j}$ is the pixel on the $i$-th row and $j$-th colum of an aligned face picture matrix and $d$ is the dimension of the matrix, which is usually two. We define the loss function for the profile images with faces as
\begin{equation}
loss_f=\underset{i,j}{\sum}\left[\left\Vert f_{emb}(px_{i,j}^{p_{1}^{t_1}})-f_{emb}(px_{i,j}^{p_{2}^{t_2}})\right\Vert _{2}^{2}\right]
\end{equation}

\noindent
\begin{customdfn}{5.1}[Profile Image Similarity with Face, $s^{F}_5$]
The face image similarity is defined as
\begin{equation}
s^F_5(p_{1}^{t_1}, p_{2}^{t_2})=\max(1-\sqrt{loss_f}, 0)
\end{equation}
\end{customdfn}

\noindent For the case when both images do not have human faces, we leverage the traditional algorithm, the scale invariant feature transform (SIFT) \cite{lowe1999object}, used for object recognition in computer vision. Let $g(x)$ represent the
number of SIFT features of picture $x$, and $m(x,y)$ be the number of matched features between picture $x$ and $y$ with Lowes's ratio test \cite{lowe2004distinctive}. 
\begin{customdfn}{5.2}[Profile Image Similarity without Face, $s^{\neg F}_5$]
\begin{equation}
\begin{gathered}
s^{\neg F}_5(p_{1}^{t_1}, p_{2}^{t_2}) = \frac{m(p_{1}^{t_1}, p_{2}^{t_2})}{\min(g(p_{1}^{t_1}),g(p_{2}^{t_2})}
\end{gathered}
\end{equation}
\end{customdfn}

Now we are ready to define our overall profile similarity:
\theoremstyle{definition}
\begin{definition}[Profile Similarity]
Let $u_{1}^{t_1}\in SN_1$ and $u_{2}^{t_2}\in SN_2$, the profile similarity $S:SN_1\times SN_2\rightarrow [0,1]$ of two user accounts is defined as
\begin{equation}
S(u_{1}^{t_1},u_{2}^{t_2})=\sum_{k=1}^{5} w_k s_k(p_{1}^{t_1},p_{2}^{t_2})
\label{def:overall}
\end{equation}
where %$p_{1}^{t_1}$ is the $k$-th profile attribute of account $u_{1}^{t_1}$ in the social network $SN_1$, $p_{2}^{t_2}$ is the $k$-th profile attribute of account $u_{2}^{t_2}$ in the social network $SN_2$, 
$s_k(p_{1}^{t_1},p_{2}^{t_2})$ represents the $k$-th attribute similarity of the two user accounts and $w_k$ is the corresponding weight that captures the impact of $s_k$ on the overall profile similarity. 
\end{definition}

In the following we present a learning based model to calculate the weights in Definition~\ref{def:overall}. %, which play a crucial rule for an effective inference. 
%Having specified all the definitions, we need to find the weights for the profile similarity, which are crucial for a correct inference. 
Intuitively, the weights should be determined by maximizing the probability of correct matches and minimizing the probability of incorrect matches. %In order to do so, we employ a learning-based method. 
Suppose we have a ground truth dataset which includes $n_{gt}$ users from $SN_{1}$ and $n_{gt}$ users from $SN_{2}$, with the $i$th user from $SN_{1}$ and the $i$th user from $SN_{2}$ are indeed the same person.
%Suppose we have a ground truth dataset which includes $n_{gt}$ users collected from $SN_{1}=\{u_{1}^{1},u_{1}^{2},\cdots,u_{1}^{n_{gt}}\}$ and $n_{gt}$ users collected from $SN_{2}=\{u_{2}^{1},u_{2}^{2},\cdots,u_{2}^{n_{gt}}\}$ such that each pair of users with the same superscript is indeed the same person. %For example, $u_{1}^{i}$ and $u_{2}^{i}$ from social networks $SN_1$ and $SN_2$ are the same person. 
Based on the profile similarity defined in Definition~\ref{def:overall}, we can get a matrix $\boldsymbol{S}$ over the pairwise profile similarity scores between $SN_{1}$ and $SN_{2}$.
%
\begin{equation}
\mathbf{S}(SN_{1},SN_{2})= \left(\begin{array}{cccc}
S(u_{1}^{1},u_{2}^{1}) & S(u_{1}^{1},u_{2}^{2}) & \ldots & S(u_{1}^{1},u_{2}^{n_{gt}})\\
S(u_{1}^{2},u_{2}^{1}) & S(u_{1}^{2},u_{2}^{2}) & \ldots & S(u_{1}^{2},u_{2}^{n_{gt}})\\
\vdots & \vdots & \ddots & \vdots\\
S(u_{1}^{n_{gt}},u_{2}^{1}) & S(u_{1}^{n_{gt}},u_{2}^{2}) & \ldots & S(u_{1}^{n_{gt}},u_{2}^{n_{gt}})
\end{array}\right)
\end{equation}
where each entry $S(u_{1}^{i}, u_{2}^{j})$ is the profile similarity score defined in Definition~\ref{def:overall}.

In order to find the proper weights, instead of considering only the incorrect matches or correct matches, we came up with a novel loss function which takes into consideration both the correct matches and the incorrect matches, making it more efficient and effective. The loss function is defined as follows:
%
\begin{equation}\label{eq:loss}
\begin{gathered}
loss=l(w_{1},w_{2},\ldots,w_{k})= \\
\left\langle \left[\left(\begin{array}{c}
1\\
1\\
\vdots\\
1
\end{array}\right)_{n_{gt}\times1}-diag(\boldsymbol{S})+\frac{1}{n_{gt}-1}\left(\begin{array}{c}
\underset{j,j\neq1}{\sum}S(u_{1}^{1},u_{2}^{j})\\
\underset{j,j\neq2}{\sum}S(u_{1}^{2},u_{2}^{j})\\
\vdots\\
\underset{j,j\neq n_{gt}}{\sum}S(u_{1}^{n_{gt}},u_{2}^{j})
\end{array}\right)\right]^{2}\right\rangle
\end{gathered}
\end{equation}
where $\left\langle \cdot \right\rangle$ represents the expectation sign. The weight vector is determined by solving the following system of equations.
\begin{equation}\label{eq:gradient}
\nabla l=0\Longrightarrow\begin{cases}
\frac{\partial l}{\partial w_{1}}=0\\
\frac{\partial l}{\partial w_{2}}=0\\
\vdots\\
\frac{\partial l}{\partial w_{k}}=0
\end{cases}
\end{equation}
In our approach, we solve the system of equations (\ref{eq:gradient}) by TensorFlow with the gradient descent optimization \cite{ruder2016overview}.

\subsection{Evaluation}
In this subsection, we report the evaluation results of our approach to demonstrate its effectiveness on the DS-SN attack within a single social network and the SN-SN attack across two social networks.

According to the design elaborated in Section~\ref{sec:dssnapproach}, we implemented the following programs: a malicious app in Java with 3280 lines of code (LOC) for collecting the publicly available Android system state data, which deals with the first step of the DS-SN attack; a server code for activity transition inference and social network event inference with 1800 LOC in Python, which handles the second and third steps of the DS-SN attack; a program of 1595 LOC in Python to crawl the databases of Twitter, Instagram, and Flickr, and perform the device-account matching, which corresponds to the fourth step of the DS-SN attack; and finally, a program with 707 LOC in Python, which performs the SN-SN user account association analysis.

In our experiments, we used five different Android devices: a Nexus 7 with Android version 6.0.1, a HTC One Sense 6 with Android version 5.0.2, a Blu R1 HD with Android version 6.0, a Huawei Honor 8 Lite with Android version 7.0, and a Samsung Galaxy S4 with Android version 4.2.2. In the server side, we used a Dell Inspiron 5559 Specs with Intel Core i7-6500U CPU @ 2.50GHz x 4 running OS Ubuntu 16.04 LTS to conduct the experiments. 

\subsubsection{Effectiveness of the DS-SN Correlation Attack}
We evaluated the effectiveness of our DS-SN attack by i) validating the memory regression learning model, ii) inferring the posting timestamps, iii) inferring the number of characters in a tweet, and iv) inferring the possible list of social network accounts associated with the victim device via multiple posting events.

\textbf{Performance of the Memory Regression Model}

As mentioned in Section~\ref{sec:dssnapproach}, we leveraged a 5-layer feedforward neural network to learn the patterns of activity transitions in Twitter and Instagram, i.e., from \texttt{MainActivity} to \texttt{ComposerActivity} in Twitter and from \texttt{MediaCaptureActivity I} to \\
\texttt{MediaCaptureActivity II} in Instagram. We wrote an automatic program in Python using the Android debug bridge (\texttt{adb})~\cite{adb} with the UI Automator framework for the generation and collection of the training data and test data. We ran the automatic \texttt{adb} Python program in all five Android devices for collecting the training data. As a result, for each of the 5 Android devices, we collected 1,900 pieces of training data for Twitter and 2,340 pieces of training data for Instagram. Thus, in total we have 9,500 pieces of training data for Twitter and 11,700 pieces of training data for Instagram. Note that each piece of the training data contains only the target activity transition - no other noisy actions such as swiping. To determine $n$ as mentioned in Section~\ref{sec:dssnapproach}, we tried multiple different values for the threshold $\delta$ and found that the values around $1000$ work pretty well for both Twitter and Instagram; thus we set $\delta=1000$. Also, we set the cessation threshold for the mean squared error to be $10^{-6}$. As a result, the mean squared error for the learning process of the Twitter activity transition drops to below $10^{-6}$ after approximately 30 minutes and the one for the Instagram activity transition drops to below $10^{-6}$ after approximately 40 minutes, which are reasonably low for deep learning models.

\begin{table*}[t]
\centering
\caption{Averaged Inference Results on the Posting Timestamps and the Number of Characters in Tweeter}
\label{tbl:posttimeinf}
\resizebox{\columnwidth}{!}{
\begin{tabular}{|c|l|c|c|c|}
\hline
\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}App \\ Name\end{tabular}} & \multicolumn{4}{c|}{Averaged Inference Results on the Posting Timestamps and the Number of Characters in Tweeter}                                                                                                                                                                                                                                                                                                                                                                                                  \\ \cline{2-5}
                                                                     & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Types of \\ Random Noisy \\Actions Performed\end{tabular}} & \begin{tabular}[c]{@{}c@{}}Accuracy of Inferrring\\ Posting Timestamps\end{tabular} & \begin{tabular}[c]{@{}c@{}}Average Difference of\\ Timestamps\\ (in seconds)\end{tabular} &  \begin{tabular}[c]{@{}c@{}}Accuracy of Inferring\\ Number of Characters\\ in Tweets\end{tabular}     \\ \hline
Twitter                                                              & \begin{tabular}[c]{@{}l@{}}1. Swiping\\ 2. Tapping\\ 3. Commenting\\\end{tabular}       & 86.99\%                                                    & 16.35                                                                                                                                            & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}37.18\% ($\epsilon=0.05$)\\ 91.86\% ($\epsilon=0.15$)\\ 98.92\% ($\epsilon=0.3$)\end{tabular}}              \\ \hline
Flickr                                                               & \begin{tabular}[c]{@{}l@{}}1. Swiping\\ 2. Tapping\\ 3. Commenting\\\end{tabular}  & 96.81\%                                                    & 15.05                                                                                                                                             & N/A                                                                                                  \\ \hline
Instagram                                                            & \begin{tabular}[c]{@{}l@{}}1. Swiping\\ 2. Tapping\\ 3. Commenting\\\end{tabular}  & 96.73\%                                                    & 19.75                                                                                                                                             & N/A                                                                                                  \\ \hline
\end{tabular}
}
\end{table*}

\textbf{Inference of the Posting Timestamps}

The automatic \texttt{adb} Python program performed 5,625 tests for all five Android devices, with each device performing 1,125 tests. Each test is for one target social network app and collects a block of data with 6 rows: \emph{VSS},  \texttt{tcp\_snd}, and \texttt{tcp\_rcv} for the social network app,  \texttt{utime} and \texttt{stime} for the keyboard process, and \emph{RSS} for the media process, and each row contains 600 values. Therefore, for each Android device, we conducted 375 tests for each target app. It took 5 to 6 minutes to perform one test, during which our automatic \texttt{adb} program controlled the target social network app to tweet with a random number of characters (Twitter) or to post a photo (Instagram and Flickr)), and recorded the system timestamps of the tweet/photo-post event (ground truth timestamps) for evaluation. The \texttt{adb} program also generated random noisy actions such as swiping, tapping, and commenting in the target apps to imitate human beings' actions on these apps during each block collection. %Then in some moments, our program controlled the target apps to tweet with a random number of characters (Twitter) or to post a photo (Instagram and Flickr), and recorded the system timestamp of the tweet/photo-post (ground truth timestamp) for evaluation.
Meanwhile, our malicious app collected \emph{VSS}, \texttt{tcp\_snd}, and \texttt{tcp\_snd} for the three social network apps and the \emph{RSS} of Android media process as shown in Table~\ref{tbl:ds-sn-summary} for the inference attack. 

We considered that a correct inference is made if the difference between the ground truth posting timestamp and our inferred posting timestamp is less than 30 seconds. 
Table~\ref{tbl:posttimeinf} reports the averaged inference results of all Android devices. As one can see, the numbers of correct inferences of the posting timestamps for Twitter, Flickr, and Instagram are 86.99\%, 96.81\%, and 96.73\%, respectively. Table~\ref{tbl:eachdeviceinfer} shows the inference results of each Android device against the three target apps. As one can see, generally speaking, our inference of posting timestamps is most effective in Nexus 7 device, and least effective in HTC One Sense 6.

Note that in our memory regression model we set $\sigma=10^5$, which was determined based on many trials. 

\begin{table}[]
\centering
\caption{Inference Results on the Posting Timestamps for Each Device}
\label{tbl:eachdeviceinfer}
\begin{tabular}{|c|c|c|c|}
\hline
\multirow{2}{*}{Device Name} & \multicolumn{3}{c|}{App Name} \\ \cline{2-4} 
                             & Twitter & Instagram & Flickr  \\ \hline
Nexus 7                      & 90.67\% & 98.67\%   & 99.73\% \\ \hline
HTC One Sense 6              & 82.93\% & 91.20\%   & 90.40\% \\ \hline
Blu R1 HD                    & 91.47\% & 87.47\%   & 98.67\% \\ \hline
Huawei Honor 8               & 84.27\% & 94.93\%   & 98.40\% \\ \hline
Samsung Galaxy S4            & 90.93\% & 85.87\%   & 98.93\% \\ \hline
\end{tabular}
\end{table}


\begin{table*}[!htb]
\centering
\caption{Attack Results on Volunteers.}
\label{tbl:volunteers}
\resizebox{1.2\columnwidth}{!}{
\hspace{-27ex}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline \hline
\multicolumn{13}{|c|}{Attack Results on Volunteers}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \\ \hline \hline
\multirow{2}{*}{\# of Timestamps} & \multicolumn{6}{c|}{\begin{tabular}[c]{@{}c@{}}Number of Potential \\ Twitter Identities\\ (Without Number-of-Character Filter)\end{tabular}} & \multicolumn{6}{c|}{\begin{tabular}[c]{@{}c@{}}Number of Potential \\ Twitter Identities\\ (With Number-of-Character Filter)\end{tabular}}                                                                                                                                                                                                                                                                                                                                                                                              \\ \cline{2-13} 
                                  & Participant 1          & Participant 2          & Participant 3          & Participant 4          & Participant 5          & Average          & Participant 1                                                                        & Participant 2                                                                        & Participant 3                                                                        & Participant 4                                                                        & Participant 5                                                                        & Average                                                                              \\ \hline
1                                 & 52,120                 & 61,810                 & 55,132                 & 51,205                 & 50,037                 & 54,060           & \begin{tabular}[c]{@{}c@{}}2,313 ($\epsilon=0.3$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}2,538 ($\epsilon=0.3$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}2,272 ($\epsilon=0.3$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}1,971 ($\epsilon=0.3$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}2,067 ($\epsilon=0.3$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}2,232 ($\epsilon=0.3$)\end{tabular} \\ \hline
2                                 & 369                    & 403                    & 331                    & 324                    & 347                    & 354              & \begin{tabular}[c]{@{}c@{}}21 ($\epsilon=0.3$)\end{tabular}       & \begin{tabular}[c]{@{}c@{}}19 ($\epsilon=0.3$)\end{tabular}       & \begin{tabular}[c]{@{}c@{}}22 ($\epsilon=0.3$)\end{tabular}       & \begin{tabular}[c]{@{}c@{}}12 ($\epsilon=0.3$)\end{tabular}       & \begin{tabular}[c]{@{}c@{}}10 ($\epsilon=0.3$)\end{tabular}       & \begin{tabular}[c]{@{}c@{}}16 ($\epsilon=0.3$)\end{tabular}       \\ \hline
3                                 & 52                     & 61                     & 71                     & 43                     & 57                     & 56               & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}2 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         \\ \hline
4                                 & 11                     & 8                      & 13                     & 9                      & 7                      & 9                & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$) \end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         \\ \hline
5                                 & 4                      & 3                      & 5                      & 4                      & 3                      & 3                & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         \\ \hline
6                                 & 3                      & 2                      & 2                      & 1                      & 1                      & 1                & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$))\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         \\ \hline
7                                 & 3                      & 2                      & 1                      & 1                      & 1                      & 1                & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         \\ \hline
8                                 & 1                      & 2                      & 1                      & 1                      & 1                      & 1                & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         \\ \hline
9                                 & 1                      & 1                      & 1                      & 1                      & 1                      & 1                & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         & \begin{tabular}[c]{@{}c@{}}1 ($\epsilon=0.3$)\end{tabular}         \\ \hline
\end{tabular}
}
\end{table*}

\textbf{Inference of the Number of Characters in a Tweet}

To evaluate the inference accuracy on the number of characters in a tweet through CPU \texttt{utime} and \texttt{stime} of the Keyboard process, we denote the actual number of characters of a tweet by $N_{act}$, the inferred number by $N_{inf}$, and set an error parameter $\epsilon$ such that our inference is considered a success if the error percentage is less than $\epsilon$, i.e., $\frac{|N_{act}-N_{inf}|}{N_{act}}\le\epsilon$. 
In order to evaluate the accuracy of our inference attacks, we randomly sampled 5,000 tweets from those of the 500,008 Twitter users collected in Section~\ref{sec:dssnapproach}, and re-tweeted these 5,000 tweets using our Android devices. By doing so, we can guarantee that the distribution of the number of characters of our posted tweets follows the one in real-world.
The average number of characters of these 5,000 tweets was 189. The results are reported in Table~\ref{tbl:posttimeinf}, which indicate that if we set $\epsilon$ to be 0.05, the possibility of correct inference is 37.18\%; if $\epsilon$ is set to 0.15, the possibility of correct inference is 91.86\%; while if $\epsilon$ is set to 0.3, the possibility increases to 98.92\%. %Table~\ref{tbl:posttimeinf} shows the detailed results. 

\textbf{Associating Device with Social Network Accounts}

We used Twitter to illustrate the performance of associating the victim device with a list of candidate social network accounts. In this evaluation, we conducted two studies, with one on the Twitter celebrities and one on five volunteers. Note that the study on Twitter celebrities cannot identify any device that is associated with a social network account because we do not install our malicious app in any legitimate user in Twitter; nevertheless, the tweeting activities of celebrities can facilitate us to figure out how many people simultaneously tweet at two or more timestamps, which provides a perfect justification to explain why we can correlate the tweeting activities at different timestamps to identify the user account associated with a victim device.

For the study on celebrities, we collected tweets from 5 active Twitter celebrities, with 10 tweets for each at different timestamps, from November 2016 to February 2017, to get the data at 50 different timestamps. Each celebrity has at least 20 million followers. We considered celebrities as our study subjects because they not only use real identities, but also are active on Twitter. The results are reported in Table~\ref{tbl:celeb-eval}, which indicate that the average number of Twitter users who tweeted at one timestamp is 52,016, at the same two timestamps is 359, at the same three timestamps is 61, and at the same four timestamps is 6. These results are interesting as one can see that the number of users who tweeted simultaneously at multiple timestamps drops significantly as the number of considered timestamps increases. 

\begin{table}[t]
\centering
\caption{Attack Results on Celebrities.}
\label{tbl:celeb-eval}
\small
\begin{tabular}{|c|c|}
\hline \hline
\multicolumn{2}{|c|}{Attack Results on Celebrities}                                              \\ \hline \hline
\# of Timestamps & \begin{tabular}[c]{@{}c@{}}Average Number of \\ Potential Twitter Identities\end{tabular} \\ \hline
1                & 52,016                                                                                    \\ \hline
2                & 359                                                                                       \\ \hline
3                & 61                                                                                        \\ \hline
4                & 6                                                                                         \\ \hline
\end{tabular}
\end{table}

Besides using celebrities as testing subjects mentioned above, we also recruited five volunteers to participate in our evaluation process. Each participant used one of our five Android devices to tweet 10 times at 10 different timestamps with his/her own Twitter account. Each tweet contained a random number of characters. The detailed results are shown in Table~\ref{tbl:volunteers}. If we do not apply the number of tweeted characters as a filter, we found that in average there are 54,060 users who tweeted at one timestamp as the volunteers did. Then the number goes to 354 at two same timestamps, 56 at three same timestamps, 9 at four same timestamps, 3 at five same timestamps, and 1 at six same timestamps. These numbers indicate that an attacker needs to conduct the inference attack for an average of six times in order to associate the Twitter account of one of our voluteers with his/her device without applying the number of characters as a filter. If we apply this filter, as one can see from the results, an attacker only needs to conduct the inference attack for an average of three times to successfully associate one volunteer with his/her Twitter account. 

\subsubsection{Performance of the SN-SN Correlation Attack}
As one can see from the results shown above, an attacker needs to infer at least three timestamps on average to correlate a user's social network account with his/her device with the estimated number of characters as a filer. Without applying this filter, on average at least 6 timestamps need to be inferred. To speed up this process, SN-SN correlation attack can be launched. In this subsection, we evaluate the performance of the SN-SN correlation attack.

Since Instagram does not provide an interface via which we can retrieve posts at any given timestamp, we considered the other two social networks: Twitter and Flickr. To proceed, we need to first derive the weight for each attribute in order to calculate the profile similarity. For this purpose we need ground truth data to train our learning model proposed in Section~\ref{sec:snsnattack}. We manually checked the tweets of a large amount of Twitter users and filtered out those who do not explicitly provide their Flickr links in one of their tweets. Finally, we obtained 20 pairs of Twitter and Flickr users we were certain that each pair actually refers to the same person. Then we applied these data to minimize the loss function in equation \eqref{eq:loss}. Finally, we obtained the following weights when the loss function reaches its stationary minimum of 0.108886: $\omega_{1}=0.509717$, $\omega_{2}=0.194603$, $\omega_{3}=0.51427$, $\omega_{4}=0.171117$ and $\omega_{5}=0.30354$. Lastly, we normalized these weights by setting $\omega_{i}^*=\frac{\omega_{i}}{|\sum_{i=1}^{5}\omega_i|}$, and obtained $\omega_{1}^*=0.301029$, $\omega_{2}^*=0.114929$, $\omega_{3}^*=0.303718$, $\omega_{4}^*=0.101058$, and $\omega_{5}^*=0.179265$.

As one can see from the above, username ($\omega_{3}$) plays an extremely important role in determining whether two users from two different social networks are actually the same person, followed by location ($\omega_{1}$).  The least important factor is biography ($\omega_{4}$), which indicates that people tend to write differently for different social networks.

\begin{figure}[t]
  \includegraphics[width=\textwidth]{SN-SN-match.pdf}
  \caption{The distribution of the matches of the fifth participant. The x-axis is the intervals of overall similarity scores while the y-axis is the number of matches.}
  \label{fig:sn-sn-match}
\end{figure}

Next we analyzed the Twitter-Flickr matching performance. We asked each of the five volunteers to send a post in Flickr with his/her Flickr account after he/she finished the 10 tweeting experiments mentioned above. Then we correlated Flickr with Twitter by considering only the first timestamp of the Twitter data of all the participants. % shown in table~\ref{tbl:volunteers} by applying an number-of-character filter of $\epsilon=0.3$. 
Next we crawled all the posts in Flickr at the five timestamps corresponding to those at which our five participants sent posts. As a result, we found that there were totally 611 Flickr users who also posted at the same timestamp at which the first participant posted. The numbers of Flickr users who posted at the same time as the second, third, fourth, and fifth participant were 533, 421, 498, and 506, respectively. Therefore, for the first participant, we analyzed a similarity matrix $\boldsymbol{S}_{p_1}$ defined in Section~\ref{sec:dssnapproach} with 1,413,243 entries ($2,313\times 611$). Similarly, the numbers of entries in the similarity matrices for the second, third, fourth, and fifth participant were 1,352,754 ($2,538\times 533$), 956,521 ($2,272\times 421$), 945,204 ($1,898\times 498$), and 1,112,188 ($2,198\times 506$), respectively. Ideally, the majority of the entries in these five matrices should contain very small values,  i.e., close to zero; while the entries for the  correct matches contain big values, i.e., close to one.

After we evaluated the five matrices with the trained weights obtained above, the similarity matrix of the first participant shows that 1,332,575 entries (94.29\%) are below 0.1; only 3 pairs whose similarity scores are greater than 0.5; and only 1 pair whose similarity score is greater than 0.65, which is the correct matching, i.e., the Twitter account and the Flickr account of the first participant. Similarly, our results showed that over 90\% of all the entries of the similarity matrices of the other four participants are below 0.1; and the correct matches corresponds to the  pairs with the highest scores. Among the results of all the five participants, the highest overall similarity score is the one for the fifth participant, which is 0.84. Figure~\ref{fig:sn-sn-match} illustrates the detailed distribution of the matches of the fifth participant as an example.
These results not only indicate that both our definitions of the attribute similarities and the weights work well in real cases, but also imply that our SN-SN correlation attack is effective in facilitating the DS-SN attack to speed up the device-identity association attack.

\subsection{Related Works}
\label{sec:related}

In this subsection, we summarize the most related work from two aspects: side-channel attacks in mobile systems and privacy attacks in social networks.

\noindent\textbf{Side-channel Attacks in Mobile Systems}. Side-channel attacks in mobile systems have been causing more and more concerns in recent years. Chen \emph{et al.} \cite{chen2014peeking} managed to infer the UI state and deploy multiple attacks based on the side-channel information such as memory, CPU, and network statistical data stealthily obtained by a zero-permission malicious app residing in the victim's smartphone. Li \emph{et al.} \cite{li2016csi} proposed a keystroke inference attack targeting mobile devices by performing the principal component analysis (PCA) on the channel state information that could be affected by the finger motions through a public WiFi hotspot. 
Zhou \emph{et al.} \cite{zhou2013identity} exploited the side-channel information of Android devices to infer a user's private information, e.g., rough location, health condition, investment, and driving route. Yang \emph{et al.}  \cite{yang2016inferring} presented an approach to discover which website a user is browsing by analyzing the USB power while the smartphone is charging. Song \emph{et al.} \cite{song2016my} managed to crack a 3D printer by reconstructing the physical prints and their corresponding G-code through scrutinizing acoustic and magnetic information obtained from Android built-in sensors. Gruss \emph{et al.} \cite{gruss2016prefetch} exploited the prefetch instructions to defeat address space layout randomization (ASLR), which is a technique to make the memory address unpredictable for an attacker to launch code-reuse attacks such as return-oriented programming (ROP). Van \emph{et al.} \cite{van2016drammer} took a step further to attack hardware by launching a row hammer attack and using timing inference to make the row hammer attack deterministic compared to prior attacks which can only succeed on a probabilistic sense. Li \emph{et al.} \cite{li2016side} proposed a side-channel attack to infer the basic living activities by analyzing the changes of the traffic sizes of encrypted video streams in smart home surveillance.
Yang \emph{et al.} \cite{yang2018study} identified and systematically analyzed a new security issue in HTML5-based hybrid mobile applications, which is termed the Origin Stripping Vulnerability (OSV), and proposed an OSV detection mechanism, namely OSV-Hunter, which leverages the \texttt{postMessage} API to defend against OSV from the root. 
Zhang \emph{et al.} \cite{zhang2018empirical} conducted an empirical study on the problem of cross-principal manipulation (XPM) of web resources, and designed a toll named XPMChecker to automatically detect XPM. An analysis generated by XPMChecker reveals that nearly 49.2\% apps from Google Play were affected by the XPM issue \cite{zhang2018empirical}.
Side-channel information is now an essential ingredient of the mobile system security.

%\noindent\textbf{Security and Privacy of Smart Device}. The security and privacy of smart devices are causing more and more concerns. %The most relevant works are aforementioned as our motivating examples. 
%Zhou \emph{et al.} \cite{zhou2013identity} managed to exploit the side-channel information of Android devices in order to infer the user's private information, e.g., rough location, health condition, investment, and driving route. Chen \emph{et al.} \cite{chen2014peeking} leveraged a Hidden Markov Model (HMM) to infer which landing \texttt{Activity}/UI a user currently resides and managed to implement serious attacks such as UI phishing and camera peeking, which could potentially result in devastating consequences. Besides these two works, side-channel based inference attacks remain a hot topic in recent years. Yang \emph{et al.}  \cite{yang2016inferring} managed to discover which website a user is browsing through analyzing the USB power while the smartphone is charging. Song \emph{et al.} \cite{song2016my} managed to crack the 3D printer by reconstructing the physical prints and their corresponding G-code through scrutinizing acoustic and magnetic information which can be obtained from Android built-in sensors. Gruss \emph{et al.} \cite{gruss2016prefetch} exploited the prefetch instructions to defeat address space layout randomization (ASLR), which is the technique to make the memory address unpredictable for an attacker to launch code-reuse attacks such as return-oriented programming (ROP). Van \emph{et al.} \cite{van2016drammer} even took a step forward to attack the hardware by launching row hammer attack and using timing inference to make the row hammer attack deterministic compared to prior attacks which can only succeed on a probabilistic sense. This attack results in rooting an Android device without exploiting any software vulnerability. Timing attack is also a serious threat to user privacy. Stone \emph{et al.} \cite{stone2013pixel} systematically analyzed web browser based timing attack such as CSS shader with WebGL and managed to sniff user browsing history and to steal pixels. Jia \emph{et al.} \cite{jia2015know} managed to accurately infer the exact residential location of a user by exploiting browser cache queries. % performing timing attack which exploits browser cache queries.

\noindent\textbf{Social Network Privacy}. Studies showed that privacy of social networks can be breached in multiple ways. Backes \emph{et al.} \cite{backes2017identity} proposed a novel link prediction inference attack between any pair of individuals in social networks based on their mobility profiles. Wondracek \emph{et al.} \cite{wondracek2010practical} demonstrated that it is possible to de-anonymize a user on a social network through his membership in specific social network groups by exploiting the browser cache in order to detect whether a user has visited certain URLs of a group. Nilizadeh \emph{et al.} \cite{nilizadeh2014community} proposed a community-based large scale de-anonymization attack using structural similarity. Ji \emph{et al.} \cite{Ji2015OnYS} presented the seed quantification requirements for perfect de-anonymizability and partial de-anonymizability of real-world social networks, which consolidate the de-anonymization at theory level. Srivatsa \emph{et al.} \cite{srivatsa2012deanonymizing}, on the other hand, leveraged mobility traces with social networks as side-channel information to uncover users' real identities. Lai \emph{et al.} \cite{lai2015anonymizing} exploited a user's interest group information to de-anonymize the users on social networks. Existing studies % not only focused on uncovering identities for social network users but also tended to reveal hidden attributes for social network users. 
also tended to reveal hidden attributes for social network users. Chaabane \emph{et al.} \cite{chaabane2012you} exploited a user's interest to explore hidden attributes of a user, e.g., age, gender, and so on. Mei \emph{et al.} \cite{Mei2018TNSE} reported an inference attack framework that integrates and modifies the existing state-of-the-art convolutional neural network models to infer a user's age. Gong \emph{et al.} \cite{gong2016you} proposed a new type of inference against user's hidden attributes such as location, occupation, and interest by analyzing both his social friending and behavioral records. 
Hassan \emph{et al.} \cite{hassan2018analysis} analyzed the privacy threats in fitness-tracking social networks and developed an attack against Endpoint Privacy Zones (EPZs) to extract a user's sensitive locations. They also presented an EPZ fuzzing technique based on geo-indistinguishability to mitigate a user's privacy leak through fitness-tracking social networks.
Many of these attacks mainly de-anonymize users based on their social relationships in a large dataset, while our approach can precisely identify the social network accounts of a target user behind a device based on the device's side-channel information, the public social network events, and the profile similarity of the user's accounts in different social networks.


%==========================================================================================================================
\section{Conclusion and Future Work}\label{sec:conclusion}
In this proposal, we mainly studied the security of Android smartphones from the perspective of system design flaw and from the perspective of side-channel information exploit. More specifically, we study the design flaw of Android Task Mechanism resulting in privilege leakage, and the public side-channel system states which leads to uncover of a user's social network identities. 

Our future research focuses on studying security and privacy for other smart devices and their corresponding systems, especially smart home devices and smart home systems. We plan to excavate the security vulnerabilities and privacy concerns of current most popular smart home devices and smart home systems, and develop new attack vectors. Afterward, we plan to design defense mechanisms to guarantee the safety and privacy of these smart home devices and systems. 

        \newpage
   \bibliographystyle{abbrv}
   \bibliography{proposal}
\end{document} 